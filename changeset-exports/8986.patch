# HG changeset patch
# User Jaroslav Hajek <highegg@gmail.com>
# Date 1237276148 -3600
#      Tue Mar 17 08:49:08 2009 +0100
# Node ID 22c8272af34bfcc66b1dc9be25b8cd6269812cd8
# Parent  193804a4f82f14a492daf2fe97c6bcffdac12475
improvements to fsolve & family

diff --git a/scripts/ChangeLog b/scripts/ChangeLog
--- a/scripts/ChangeLog
+++ b/scripts/ChangeLog
@@ -1,8 +1,18 @@
+2009-03-17  Jaroslav Hajek  <highegg@gmail.com>
+
+	* optimization/__fdjac__.m: Pass in fvec to save one evaluation.
+	* optimization/fsolve.m: Avoid redundant reevaluation when using
+	FD jacobians. Document how it can be done with user jacobians.  Make
+	first iteration special and call outputfcn after it. Skip updates
+	unless two successful iterations have occured.
+	* optimization/__dogleg__.m: Add missing alpha in the zero-gradient
+	case.
+
 2009-03-14  Jaroslav Hajek  <highegg@gmail.com>
 
 	* statistics/base/var.m: a -> x.
 
 2009-03-13  Jaroslav Hajek  <highegg@gmail.com>
 
 	* statistics/base/mean.m: Simplify.
 	* statistics/base/meansq.m: Optimize.
diff --git a/scripts/optimization/__dogleg__.m b/scripts/optimization/__dogleg__.m
--- a/scripts/optimization/__dogleg__.m
+++ b/scripts/optimization/__dogleg__.m
@@ -48,15 +48,16 @@ function x = __dogleg__ (r, b, d, delta)
         dxn = delta/xn; snmd = snm/delta;
         t = (bn/sn) * (bn/xn) * snmd;
         t -= dxn * snmd^2 - sqrt ((t-dxn)^2 + (1-dxn^2)*(1-snmd^2));
         alpha = dxn*(1-snmd^2) / t;
       else
         alpha = 0;
       endif
     else
+      alpha = delta / xn;
       snm = 0;
     endif
     ## Form the appropriate convex combination.
     x = alpha * x + ((1-alpha) * min (snm, delta)) * s;
   endif
 endfunction
 
diff --git a/scripts/optimization/__fdjac__.m b/scripts/optimization/__fdjac__.m
--- a/scripts/optimization/__fdjac__.m
+++ b/scripts/optimization/__fdjac__.m
@@ -12,28 +12,26 @@
 ## MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 ## General Public License for more details.
 ##
 ## You should have received a copy of the GNU General Public License
 ## along with Octave; see the file COPYING.  If not, see
 ## <http://www.gnu.org/licenses/>.
 
 ## -*- texinfo -*-
-## @deftypefn{Function File} {[@var{fval}, @var{fjac}]} =  __fdjac__ (@var{fcn}, @var{x}, @var{err})
+## @deftypefn{Function File} {} __fdjac__ (@var{fcn}, @var{x}, @var{fvec}, @var{err})
 ## Undocumented internal function.
 ## @end deftypefn
 
-function [fvec, fjac] = __fdjac__ (fcn, x, err = 0)
+function fjac = __fdjac__ (fcn, x, fvec, err = 0)
   err = sqrt (max (eps, err));
-  fvec = fcn (x);
-  fv = fvec(:);
   h = abs (x(:))*err;
   h(h == 0) = err;
-  fjac = zeros (length (fv), numel (x));
+  fjac = zeros (length (fvec), numel (x));
   for i = 1:numel (x)
     x1 = x;
     x1(i) += h(i);
-    fjac(:,i) = (fcn (x1)(:) - fv) / h(i);
+    fjac(:,i) = (fcn (x1)(:) - fvec) / h(i);
   endfor
 endfunction
 
 
 
diff --git a/scripts/optimization/fsolve.m b/scripts/optimization/fsolve.m
--- a/scripts/optimization/fsolve.m
+++ b/scripts/optimization/fsolve.m
@@ -67,20 +67,58 @@
 ## Last relative step size was less that TolX.
 ## @item 3
 ## Last relative decrease in residual was less than TolF. 
 ## @item 0
 ## Iteration limit exceeded.
 ## @item -3
 ## The trust region radius became excessively small. 
 ## @end table
-##
+## 
 ## Note: If you only have a single nonlinear equation of one variable, using 
 ## @code{fzero} is usually a much better idea.
 ## @seealso{fzero, optimset}
+##
+## Note about user-supplied jacobians:
+## As an inherent property of the algorithm, jacobian is always requested for a
+## solution vector whose residual vector is already known, and it is the last
+## accepted successful step. Often this will be one of the last two calls, but
+## not always. If the savings by reusing intermediate results from residual
+## calculation in jacobian calculation are significant, the best strategy is to
+## employ OutputFcn: After a vector is evaluated for residuals, if OutputFcn is
+## called with that vector, then the intermediate results should be saved for
+## future jacobian evaluation, and should be kept until a jacobian evaluation
+## is requested or until outputfcn is called with a different vector, in which
+## case they should be dropped in favor of this most recent vector. A short
+## example how this can be achieved follows:
+## @example
+## function [fvec, fjac] = my_optim_func (x, optimvalues, state)
+## persistent sav = [], sav0 = [];
+## if (nargin == 1)
+##   ## evaluation call
+##   if (nargout == 1)
+##     sav0.x = x; # mark saved vector
+##     ## calculate fvec, save results to sav0.
+##   elseif (nargout == 2)
+##     ## calculate fjac using sav.
+##   endif
+## else
+##   ## outputfcn call.
+##   if (all (x == sav0.x))
+##     sav = sav0;
+##   endif
+##   ## maybe output iteration status etc.
+## endif
+## endfunction
+##
+## ## ....
+## 
+## fsolve (@my_optim_func, x0, optimset ("OutputFcn", @my_optim_func, @dots{}))
+## @end example
+###
 ## @end deftypefn
 
 ## PKG_ADD: __all_opts__ ("fsolve");
 
 function [x, fvec, info, output, fjac] = fsolve (fcn, x0, options = struct ())
 
   ## Get default options if requested.
   if (nargin == 1 && ischar (fcn) && strcmp (fcn, 'defaults'))
@@ -124,42 +162,61 @@ function [x, fvec, info, output, fjac] =
   tolx = optimget (options, "TolX", sqrt (macheps));
   tolf = optimget (options, "TolFun", sqrt (macheps));
 
   factor = 100;
   ## FIXME: TypicalX corresponds to user scaling (???)
   autodg = true;
 
   niter = 1;
-  nfev = 0;
+  nfev = 1;
 
   x = x0(:);
   info = 0;
 
+  ## Initial evaluation.
+  fvec = fcn (reshape (x, xsiz));
+  fsiz = size (fvec);
+  fvec = fvec(:);
+  fn = norm (fvec);
+  m = length (fvec);
+  n = length (x);
+
+  if (! isempty (outfcn))
+    optimvalues.iter = niter;
+    optimvalues.funccount = nfev;
+    optimvalues.fval = fn;
+    optimvalues.searchdirection = zeros (n, 1);
+    state = 'init';
+    stop = outfcn (x, optimvalues, state);
+    if (stop)
+      info = -1;
+      break;
+    endif
+  endif
+
+  nsuciter = 0;
+
   ## Outer loop.
   while (niter < maxiter && nfev < maxfev && ! info)
 
     ## Calculate function value and Jacobian (possibly via FD).
     ## Handle arbitrary shapes of x and f and remember them.
     if (has_jac)
       [fvec, fjac] = fcn (reshape (x, xsiz));
       ## If the jacobian is sparse, disable Broyden updating.
       if (issparse (fjac))
         updating = false;
       endif
+      fvec = fvec(:);
       nfev ++;
     else
-      [fvec, fjac] = __fdjac__ (fcn, reshape (x, xsiz));
-      nfev += 1 + length (x);
+      fjac = __fdjac__ (fcn, reshape (x, xsiz), fvec);
+      nfev += length (x);
     endif
-    fsiz = size (fvec);
-    fvec = fvec(:);
-    fn = norm (fvec);
-    m = length (fvec);
-    n = length (x);
 
     ## For square and overdetermined systems, we update a QR
     ## factorization of the jacobian to avoid solving a full system in each
     ## step. In this case, we pass a triangular matrix to __dogleg__.
     useqr = updating && m >= n && n > 10;
 
     if (useqr)
       ## FIXME: Currently, pivoting is mostly useless because the \ operator
@@ -194,16 +251,17 @@ function [x, fvec, info, output, fjac] =
       dg = max (0.1*dg, jcn);
 
       ## It also seems that in the case of fast (and inhomogeneously) changing
       ## jacobian, the Broyden updates are of little use, so maybe we could
       ## skip them if a big disproportional change is expected. The question is,
       ## of course, how to define the above terms :)
     endif
 
+    lastratio = 0;
     nfail = 0;
     nsuc = 0;
     ## Inner loop.
     while (niter <= maxiter && nfev < maxfev && ! info)
 
       if (useqr)
         tr_mat = r;
         tr_vec = q'*fvec;
@@ -244,41 +302,43 @@ function [x, fvec, info, output, fjac] =
         prered = 1 - (t/fn)^2;
         ratio = actred / prered;
       else
         prered = 0;
         ratio = 0;
       endif
 
       ## Update delta.
-      if (ratio < 0.1)
+      if (ratio < min(max(0.1, lastratio), 0.9))
         nsuc = 0;
         nfail ++;
         delta *= 0.5;
         if (delta <= 1e1*macheps*xn)
           ## Trust region became uselessly small.
           info = -3;
           break;
         endif
       else
+        lastratio = ratio;
         nfail = 0;
         nsuc ++;
         if (abs (1-ratio) <= 0.1)
           delta = 2*sn;
         elseif (ratio >= 0.5 || nsuc > 1)
           delta = max (delta, 2*sn);
         endif
       endif
 
       if (ratio >= 1e-4)
         ## Successful iteration.
         x += s;
         xn = norm (dg .* x);
         fvec = fvec1;
         fn = fn1;
+        nsuciter ++;
       endif
 
       niter ++;
 
       ## FIXME: should outputfcn be only called after a successful iteration?
       if (! isempty (outfcn))
         optimvalues.iter = niter;
         optimvalues.funccount = nfev;
@@ -316,17 +376,17 @@ function [x, fvec, info, output, fjac] =
 	  ## for two different tests, but that's what M*b manual appears
 	  ## to say.
         elseif (actred < tolf)
           info = 3;
         endif
       endif
 
       ## Criterion for recalculating jacobian.
-      if (! updating || nfail == 2)
+      if (! updating || nfail == 2 || nsuciter < 2)
         break;
       endif
 
       ## Compute the scaled Broyden update.
       if (useqr)
         u = (fvec1 - q*w) / sn; 
         v = dg .* ((dg .* s) / sn);
 
@@ -342,16 +402,17 @@ function [x, fvec, info, output, fjac] =
     endwhile
   endwhile
 
   ## Restore original shapes.
   x = reshape (x, xsiz);
   fvec = reshape (fvec, fsiz);
 
   output.iterations = niter;
+  output.successful = nsuciter;
   output.funcCount = nfev;
 
 endfunction
 
 ## An assistant function that evaluates a function handle and checks for
 ## bad results.
 function [fx, jx] = guarded_eval (fun, x, complexeqn)
   if (nargout > 1)
