# HG changeset patch
# User John W. Eaton <jwe@octave.org>
# Date 1233348171 18000
#      Fri Jan 30 15:42:51 2009 -0500
# Node ID ff61b53eb294138add7d31365ac1444324e4dc04
# Parent  06f5dd901f301c7f87127004846d410046f26623
optimization: use PKG_ADD: comments instead of PKG_ADD file

diff --git a/scripts/ChangeLog b/scripts/ChangeLog
--- a/scripts/ChangeLog
+++ b/scripts/ChangeLog
@@ -1,8 +1,14 @@
+2009-01-30  John W. Eaton  <jwe@octave.org>
+
+	* optimization/PKG_ADD: Delete.
+	* optimization/fsolve.m, optimization/fzero.m,
+	optimization/lsqnonneg.m: Use PKG_ADD: comment to call __all_opts__.
+
 2009-01-30  Jaroslav Hajek  <highegg@gmail.com>
 
 	* optimization/__all_opts__.m: New source.
 	* optimization/optimset.m: Implement checking for registered options.
 	* optimization/optimget.m: Ditto.
 	* optimization/fsolve.m: Fix misspelled option.
 	* optimization/PKG_ADD: New startup file.
 
diff --git a/scripts/optimization/PKG_ADD b/scripts/optimization/PKG_ADD
deleted file mode 100644
--- a/scripts/optimization/PKG_ADD
+++ /dev/null
@@ -1,2 +0,0 @@
-__all_opts__ ("fzero", "fsolve", "lsqnonneg");
-
diff --git a/scripts/optimization/fsolve.m b/scripts/optimization/fsolve.m
--- a/scripts/optimization/fsolve.m
+++ b/scripts/optimization/fsolve.m
@@ -67,16 +67,18 @@
 ## The trust region radius became excessively small. 
 ## @end table
 ##
 ## Note: If you only have a single nonlinear equation of one variable, using 
 ## @code{fzero} is usually a much better idea.
 ## @seealso{fzero, optimset}
 ## @end deftypefn
 
+## PKG_ADD: __all_opts__ ("fsolve");
+
 function [x, fvec, info, output, fjac] = fsolve (fcn, x0, options = struct ())
 
   ## Get default options if requested.
   if (nargin == 1 && ischar (fcn) && strcmp (fcn, 'defaults'))
     x = optimset ("MaxIter", 400, "MaxFunEvals", Inf, \
     "Jacobian", "off", "TolX", 1.5e-8, "TolFun", 1.5e-8,
     "OutputFcn", [], "Updating", "on", "FunValCheck", "off");
     return;
diff --git a/scripts/optimization/fzero.m b/scripts/optimization/fzero.m
--- a/scripts/optimization/fzero.m
+++ b/scripts/optimization/fzero.m
@@ -54,16 +54,18 @@
 ## been transformed non-trivially; instead of the authors' approach of
 ## sequentially calling building blocks subprograms we implement here a
 ## FSM version using one interior point determination and one bracketing
 ## per iteration, thus reducing the number of temporary variables and
 ## simplifying the algorithm structure. Further, this approach reduces
 ## the need for external functions and error handling. The algorithm has
 ## also been slightly modified.
 
+## PKG_ADD: __all_opts__ ("fzero");
+
 function [x, fval, info, output] = fzero (fun, x0, options = struct ())
 
   ## Get default options if requested.
   if (nargin == 1 && ischar (fun) && strcmp (fun, 'defaults'))
     x = optimset ("MaxIter", Inf, "MaxFunEvals", Inf, "TolX", 0, \
     "OutputFcn", [], "FunValCheck", "off");
     return;
   endif
diff --git a/scripts/optimization/lsqnonneg.m b/scripts/optimization/lsqnonneg.m
--- a/scripts/optimization/lsqnonneg.m
+++ b/scripts/optimization/lsqnonneg.m
@@ -53,16 +53,18 @@
 ## @end itemize
 ## @item lambda
 ##
 ## Not implemented.
 ## @end itemize
 ## @seealso{optimset}
 ## @end deftypefn
 
+## PKG_ADD: __all_opts__ ("lsqnonneg");
+
 ## This is implemented from Lawson and Hanson's 1973 algorithm on page
 ## 161 of Solving Least Squares Problems.
 
 function [x, resnorm, residual, exitflag, output, lambda] = lsqnonneg (c, d, x = [], options = struct ())
 
   if (nargin == 1 && ischar (c) && strcmp (c, 'defaults'))
     x = optimset ("MaxIter", 1e5);
     return
