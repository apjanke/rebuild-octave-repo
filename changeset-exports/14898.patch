# HG changeset patch
# User Andy Adler <andy@analyti.ca>
# Date 1342813168 25200
#      Fri Jul 20 12:39:28 2012 -0700
# Node ID f8bb15f6a19b8c8ea87c4fe638eaf46bf793c27b
# Parent  8e2a6fc55787024856c4d25181f643f07ed13b0e
doc: Add "Display" option to optimset documentation.

* optimset.m: Add "Display" option to optimset documentation.

diff --git a/scripts/optimization/optimset.m b/scripts/optimization/optimset.m
--- a/scripts/optimization/optimset.m
+++ b/scripts/optimization/optimset.m
@@ -21,26 +21,44 @@
 ## @deftypefn  {Function File} {} optimset ()
 ## @deftypefnx {Function File} {} optimset (@var{par}, @var{val}, @dots{})
 ## @deftypefnx {Function File} {} optimset (@var{old}, @var{par}, @var{val}, @dots{})
 ## @deftypefnx {Function File} {} optimset (@var{old}, @var{new})
 ## Create options struct for optimization functions.
 ##
 ## Valid parameters are:
 ##
-## @itemize @bullet
+## @table @asis
 ## @item AutoScaling
 ##
 ## @item ComplexEqn
 ##
+## @item Display
+## Request verbose display of results from optimizations.  Values are:
+##
+## @table @asis
+## @item "off" [default]
+## No display.
+##
+## @item "iter"
+## Display intermediate results for every loop iteration.
+##
+## @item "final"
+## Display the result of the final loop iteration.
+##
+## @item "notify"
+## Display the result of the final loop iteration if the function has
+## failed to converge.
+## @end table
+##
 ## @item FinDiffType
 ##
 ## @item FunValCheck
 ## When enabled, display an error if the objective function returns an invalid
-## value (a complex value, NaN, or Inf).  Must be set to "on" or "off"
+## value (a complex number, NaN, or Inf).  Must be set to "on" or "off"
 ## [default].  Note: the functions @code{fzero} and @code{fminbnd} correctly
 ## handle Inf values and only complex values or NaN will cause an error in this
 ## case. 
 ##
 ## @item GradObj
 ## When set to "on", the function to be minimized must return a second argument
 ## which is the gradient, or first derivative, of the function at the point
 ## @var{x}.  If set to "off" [default], the gradient is computed via finite
@@ -72,17 +90,17 @@
 ## @item TolX
 ## Termination criterion for the function input.  If the difference in @var{x},
 ## the current search point, between one algorithm iteration and the next is
 ## less than @code{TolX} the optimization stops.  Must be a positive scalar.
 ##
 ## @item TypicalX
 ##
 ## @item Updating
-## @end itemize
+## @end table
 ## @end deftypefn
 
 function retval = optimset (varargin)
 
   nargs = nargin ();
 
   ## Add more as needed.
   opts = __all_opts__ ();
