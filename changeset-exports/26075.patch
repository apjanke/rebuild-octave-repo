# HG changeset patch
# User Kai T. Ohlhus <k.ohlhus@gmail.com>
# Date 1542293773 -3600
#      Thu Nov 15 15:56:13 2018 +0100
# Node ID 5d28fc32a7c77eddc3071fcdf8f0d033cf226243
# Parent  1861e2ea0a4b4d03a36af886f64d54293ca2064d
doc: Consistent use of "fval" for optimization functions.

* scripts/optimization/fsolve(): Replaced occurrences of "fvec" by "fval".
This does not change any functionality in the code and test cases.  Improved
the docstring.

Now fsolve, fzero, fminsearch, fminbnd, and fminunc consistenly use "fval" for
the objective function value.  Only fsolve has been an exception so far.

This inconsistency was reported by
https://lists.gnu.org/archive/html/help-octave/2018-11/msg00032.html

diff --git a/scripts/optimization/fsolve.m b/scripts/optimization/fsolve.m
--- a/scripts/optimization/fsolve.m
+++ b/scripts/optimization/fsolve.m
@@ -16,17 +16,17 @@
 ## along with Octave; see the file COPYING.  If not, see
 ## <https://www.gnu.org/licenses/>.
 ##
 ## Author: Jaroslav Hajek <highegg@gmail.com>
 
 ## -*- texinfo -*-
 ## @deftypefn  {} {} fsolve (@var{fcn}, @var{x0})
 ## @deftypefnx {} {} fsolve (@var{fcn}, @var{x0}, @var{options})
-## @deftypefnx {} {[@var{x}, @var{fvec}, @var{info}, @var{output}, @var{fjac}] =} fsolve (@dots{})
+## @deftypefnx {} {[@var{x}, @var{fval}, @var{info}, @var{output}, @var{fjac}] =} fsolve (@dots{})
 ## Solve a system of nonlinear equations defined by the function @var{fcn}.
 ##
 ## @var{fcn} should accept a vector (array) defining the unknown variables,
 ## and return a vector of left-hand sides of the equations.  Right-hand sides
 ## are defined to be zeros.  In other words, this function attempts to
 ## determine a vector @var{x} such that @code{@var{fcn} (@var{x})} gives
 ## (approximately) all zeros.
 ##
@@ -36,21 +36,21 @@
 ##
 ## @var{options} is a structure specifying additional parameters which
 ## control the algorithm.  Currently, @code{fsolve} recognizes these options:
 ## @qcode{"AutoScaling"}, @qcode{"ComplexEqn"}, @qcode{"FinDiffType"},
 ## @qcode{"FunValCheck"}, @qcode{"Jacobian"}, @qcode{"MaxFunEvals"},
 ## @qcode{"MaxIter"}, @qcode{"OutputFcn"}, @qcode{"TolFun"}, @qcode{"TolX"},
 ## @qcode{"TypicalX"}, and @qcode{"Updating"}.
 ##
-## If @qcode{"AutoScaling"} is on, the variables will be automatically scaled
-## according to the column norms of the (estimated) Jacobian.  As a result,
-## @code{TolFun} becomes scaling-independent.  By default, this option is off
-## because it may sometimes deliver unexpected (though mathematically
-## correct) results.
+## If @qcode{"AutoScaling"} is @qcode{"on"}, the variables will be
+## automatically scaled according to the column norms of the (estimated)
+## Jacobian.  As a result, @qcode{"TolFun"} becomes scaling-independent.  By
+## default, this option is @qcode{"off"} because it may sometimes deliver
+## unexpected (though mathematically correct) results.
 ##
 ## If @qcode{"ComplexEqn"} is @qcode{"on"}, @code{fsolve} will attempt to solve
 ## complex equations in complex variables, assuming that the equations possess
 ## a complex derivative (i.e., are holomorphic).  If this is not what you want,
 ## you should unpack the real and imaginary parts of the system to get a real
 ## system.
 ##
 ## If @qcode{"Jacobian"} is @qcode{"on"}, it specifies that @var{fcn}---when
@@ -106,17 +106,17 @@
 ##
 ## @var{output} is a structure containing runtime information about the
 ## @code{fsolve} algorithm.  Fields in the structure are:
 ##
 ## @table @code
 ## @item iterations
 ##  Number of iterations through loop.
 ##
-## @item succesful
+## @item successful
 ##  Number of successful iterations.
 ##
 ## @item @nospell{funcCount}
 ##  Number of function evaluations.
 ##
 ## @end table
 ##
 ## The final output @var{fjac} contains the value of the Jacobian evaluated
@@ -134,23 +134,23 @@
 ## employ @code{OutputFcn}: After a vector is evaluated for residuals, if
 ## @code{OutputFcn} is called with that vector, then the intermediate results
 ## should be saved for future Jacobian evaluation, and should be kept until a
 ## Jacobian evaluation is requested or until @code{OutputFcn} is called with a
 ## different vector, in which case they should be dropped in favor of this most
 ## recent vector.  A short example how this can be achieved follows:
 ##
 ## @example
-## function [fvec, fjac] = user_func (x, optimvalues, state)
+## function [fval, fjac] = user_func (x, optimvalues, state)
 ## persistent sav = [], sav0 = [];
 ## if (nargin == 1)
 ##   ## evaluation call
 ##   if (nargout == 1)
 ##     sav0.x = x; # mark saved vector
-##     ## calculate fvec, save results to sav0.
+##     ## calculate fval, save results to sav0.
 ##   elseif (nargout == 2)
 ##     ## calculate fjac using sav.
 ##   endif
 ## else
 ##   ## outputfcn call.
 ##   if (all (x == sav0.x))
 ##     sav = sav0;
 ##   endif
@@ -163,17 +163,17 @@
 ## fsolve (@@user_func, x0, optimset ("OutputFcn", @@user_func, @dots{}))
 ## @end example
 ## @seealso{fzero, optimset}
 ## @end deftypefn
 
 ## PKG_ADD: ## Discard result to avoid polluting workspace with ans at startup.
 ## PKG_ADD: [~] = __all_opts__ ("fsolve");
 
-function [x, fvec, info, output, fjac] = fsolve (fcn, x0, options = struct ())
+function [x, fval, info, output, fjac] = fsolve (fcn, x0, options = struct ())
 
   ## Get default options if requested.
   if (nargin == 1 && ischar (fcn) && strcmp (fcn, "defaults"))
     x = optimset ("AutoScaling", "off", "ComplexEqn", "off",
                   "FunValCheck", "off", "FinDiffType", "forward",
                   "Jacobian", "off",  "MaxFunEvals", [], "MaxIter", 400,
                   "OutputFcn", [], "Updating", "off", "TolFun", 1e-6,
                   "TolX", 1e-6, "TypicalX", []);
@@ -228,62 +228,62 @@ function [x, fvec, info, output, fjac] =
   niter = 1;
   nfev = 1;
 
   x = x0(:);
   info = 0;
 
   ## Initial evaluation.
   ## Handle arbitrary shapes of x and f and remember them.
-  fvec = fcn (reshape (x, xsiz));
-  fsiz = size (fvec);
-  fvec = fvec(:);
-  fn = norm (fvec);
-  m = length (fvec);
+  fval = fcn (reshape (x, xsiz));
+  fsiz = size (fval);
+  fval = fval(:);
+  fn = norm (fval);
+  m = length (fval);
   n = length (x);
 
   if (! isempty (outfcn))
     optimvalues.iter = niter;
     optimvalues.funccount = nfev;
     optimvalues.fval = fn;
     optimvalues.searchdirection = zeros (n, 1);
     state = "init";
     stop = outfcn (x, optimvalues, state);
     if (stop)
       info = -1;
       return;
     endif
   endif
 
-  if (isa (x0, "single") || isa (fvec, "single"))
+  if (isa (x0, "single") || isa (fval, "single"))
     macheps = eps ("single");
   else
     macheps = eps ("double");
   endif
 
   nsuciter = 0;
 
   ## Outer loop.
   while (niter < maxiter && nfev < maxfev && ! info)
 
     ## Calculate function value and Jacobian (possibly via FD).
     if (has_jac)
-      [fvec, fjac] = fcn (reshape (x, xsiz));
+      [fval, fjac] = fcn (reshape (x, xsiz));
       if (! all (size (fjac) == [m, n]))
         error ("fsolve: Jacobian size should be (%d,%d), not (%d,%d)",
                m, n, rows (fjac), columns (fjac));
       endif
       ## If the Jacobian is sparse, disable Broyden updating.
       if (issparse (fjac))
         updating = false;
       endif
-      fvec = fvec(:);
+      fval = fval(:);
       nfev += 1;
     else
-      fjac = __fdjac__ (fcn, reshape (x, xsiz), fvec, typicalx, cdif);
+      fjac = __fdjac__ (fcn, reshape (x, xsiz), fval, typicalx, cdif);
       nfev += (1 + cdif) * length (x);
     endif
 
     ## For square and overdetermined systems, we update a QR factorization of
     ## the Jacobian to avoid solving a full system in each step.  In this case,
     ## we pass a triangular matrix to __dogleg__.
     useqr = updating && m >= n && n > 10;
 
@@ -335,35 +335,35 @@ function [x, fvec, info, output, fjac] =
     while (niter <= maxiter && nfev < maxfev && ! info)
 
       ## Get trust-region model (dogleg) minimizer.
       if (useqr)
         if (norm (r, 1) < macheps * rows (r))
           info = -2;
           break;
         endif
-        qtf = q'*fvec;
+        qtf = q'*fval;
         s = - __dogleg__ (r, qtf, dg, delta);
         w = qtf + r * s;
       else
         if (norm (fjac, 1) < macheps * rows (fjac))
           info = -2;
           break;
         endif
-        s = - __dogleg__ (fjac, fvec, dg, delta);
-        w = fvec + fjac * s;
+        s = - __dogleg__ (fjac, fval, dg, delta);
+        w = fval + fjac * s;
       endif
 
       sn = norm (dg .* s);
       if (niter == 1)
         delta = min (delta, sn);
       endif
 
-      fvec1 = fcn (reshape (x + s, xsiz)) (:);
-      fn1 = norm (fvec1);
+      fval1 = fcn (reshape (x + s, xsiz)) (:);
+      fn1 = norm (fval1);
       nfev += 1;
 
       if (fn1 < fn)
         ## Scaled actual reduction.
         actred = 1 - (fn1/fn)^2;
       else
         actred = -1;
       endif
@@ -402,17 +402,17 @@ function [x, fvec, info, output, fjac] =
           delta = max (delta, 1.4142*sn);
         endif
       endif
 
       if (ratio >= 1e-4)
         ## Successful iteration.
         x += s;
         xn = norm (dg .* x);
-        fvec = fvec1;
+        fval = fval1;
         fn = fn1;
         nsuciter += 1;
       endif
 
       niter += 1;
 
       ## FIXME: should outputfcn be only called after a successful iteration?
       if (! isempty (outfcn))
@@ -458,34 +458,34 @@ function [x, fvec, info, output, fjac] =
 
       ## Criterion for recalculating Jacobian.
       if (! updating || nfail == 2 || nsuciter < 2)
         break;
       endif
 
       ## Compute the scaled Broyden update.
       if (useqr)
-        u = (fvec1 - q*w) / sn;
+        u = (fval1 - q*w) / sn;
         v = dg .* ((dg .* s) / sn);
 
         ## Update the QR factorization.
         [q, r] = qrupdate (q, r, u, v);
       else
-        u = (fvec1 - w);
+        u = (fval1 - w);
         v = dg .* ((dg .* s) / sn);
 
         ## update the Jacobian
         fjac += u * v';
       endif
     endwhile
   endwhile
 
   ## Restore original shapes.
   x = reshape (x, xsiz);
-  fvec = reshape (fvec, fsiz);
+  fval = reshape (fval, fsiz);
 
   output.iterations = niter;
   output.successful = nsuciter;
   output.funcCount = nfev;
 
 endfunction
 
 ## A helper function that evaluates a function and checks for bad results.
@@ -671,18 +671,18 @@ endfunction
 %! assert (norm (x - x_opt, Inf) < tol);
 
 %!test <*53991>
 %! A = @(lam) [0 1 0 0; 0 0 1 0; 0 0 0 1; 0 0 -lam^2 0];
 %! C = [1 0 0 0; 0 0 1 0];
 %! B = @(lam) [C*expm(A(lam)*0); C*expm(A(lam)*1)];
 %! detB = @(lam) det (B(lam));
 %!
-%! [x, fvec, info] = fsolve (detB, 0);
+%! [x, fval, info] = fsolve (detB, 0);
 %! assert (x == 0);
-%! assert (fvec == -1);
+%! assert (fval == -1);
 %! assert (info == -2);
 
 %!test <*53991>
-%! [x, fvec, info] = fsolve (@(x) 5*x, 0);
+%! [x, fval, info] = fsolve (@(x) 5*x, 0);
 %! assert (x == 0);
-%! assert (fvec == 0);
+%! assert (fval == 0);
 %! assert (info == 1);
