# HG changeset patch
# User Jaroslav Hajek <highegg@gmail.com>
# Date 1232965756 -3600
#      Mon Jan 26 11:29:16 2009 +0100
# Node ID c136d313206a8e002445e600ca902fc51739aaa6
# Parent  0131fa223dbc9dffaea9e27e367d865c41ad516c
improvements to fsolve

diff --git a/scripts/ChangeLog b/scripts/ChangeLog
--- a/scripts/ChangeLog
+++ b/scripts/ChangeLog
@@ -1,8 +1,16 @@
+2009-01-17  Jaroslav Hajek  <highegg@gmail.com>
+
+	* optimization/__fdjac__.m: Fix setting up h.
+	* optimization/fsolve.m: Allow underdetermined systems. Use QR for
+	large enough square and overdetermined systems, with pivoting in the
+	first step. Simplify options. Adjust defaults - make TR radius
+	tolerance less stringent. Support DisplayFcn.
+
 2008-12-24 Ben Abbott <bpabbott@mac.com>
 
 	* path/savepath.m: Respect cmd-line and env paths.
 
 2009-01-24 Ben Abbott <bpabbott@mac.com>
 
 	* sparse/svds.m: svds.m: skip tests if ARPACK is missing.
 
diff --git a/scripts/optimization/__fdjac__.m b/scripts/optimization/__fdjac__.m
--- a/scripts/optimization/__fdjac__.m
+++ b/scripts/optimization/__fdjac__.m
@@ -19,17 +19,17 @@
 ## -*- texinfo -*-
 ## @deftypefn{Function File} {[@var{fval}, @var{fjac}]} =  __fdjac__ (@var{fcn}, @var{x}, @var{err})
 ## @end deftypefn
 
 function [fvec, fjac] = __fdjac__ (fcn, x, err = 0)
   err = sqrt (max (eps, err));
   fvec = fcn (x);
   fv = fvec(:);
-  h = max (abs (x(:))*err, (norm (fv, Inf)*eps)/realmax);
+  h = abs (x(:))*err;
   h(h == 0) = err;
   fjac = zeros (length (fv), numel (x));
   for i = 1:numel (x)
     x1 = x;
     x1(i) += h(i);
     fjac(:,i) = (fcn (x1)(:) - fv) / h(i);
   endfor
 endfunction
diff --git a/scripts/optimization/fsolve.m b/scripts/optimization/fsolve.m
--- a/scripts/optimization/fsolve.m
+++ b/scripts/optimization/fsolve.m
@@ -1,9 +1,9 @@
-## Copyright (C) 2008 VZLU Prague, a.s.
+## Copyright (C) 2008, 2009 VZLU Prague, a.s.
 ##
 ## This file is part of Octave.
 ##
 ## Octave is free software; you can redistribute it and/or modify it
 ## under the terms of the GNU General Public License as published by
 ## the Free Software Foundation; either version 3 of the License, or (at
 ## your option) any later version.
 ##
@@ -27,25 +27,32 @@
 ## are defined to be zeros.
 ## In other words, this function attempts to determine a vector @var{x} such 
 ## that @code{@var{fcn} (@var{x})} gives (approximately) all zeros.
 ## @var{x0} determines a starting guess. The shape of @var{x0} is preserved
 ## in all calls to @var{fcn}, but otherwise it is treated as a column vector.
 ## @var{options} is a structure specifying additional options.
 ## Currently, @code{fsolve} recognizes these options:
 ## @code{"FunValCheck"}, @code{"OutputFcn"}, @code{"TolX"},
-## @code{"TolFun"}, @code{"MaxIter"}, @code{"MaxFunEvals"}, and
-## @code{"Jacobian"}.
+## @code{"TolFun"}, @code{"MaxIter"}, @code{"MaxFunEvals"}, 
+## @code{"Jacobian"} and @code{"Updating"}. 
 ##
 ## If @code{"Jacobian"} is @code{"on"}, it specifies that @var{fcn},
 ## called with 2 output arguments, also returns the Jacobian matrix
 ## of right-hand sides at the requested point.  @code{"TolX"} specifies
 ## the termination tolerance in the unknown variables, while 
 ## @code{"TolFun"} is a tolerance for equations. Default is @code{1e1*eps}
 ## for @code{"TolX"} and @code{1e2*eps} for @code{"TolFun"}.
+## If @code{"Updating"} is true, the function will attempt to use Broyden
+## updates to update the Jacobian, in order to reduce the amount of jacobian
+## calculations.
+## If your user function always calculates the Jacobian (regardless of number
+## of output arguments), this option provides no advantage and should be set to
+## false.
+## 
 ## For description of the other options, see @code{optimset}.
 ##
 ## On return, @var{fval} contains the value of the function @var{fcn}
 ## evaluated at @var{x}, and @var{info} may be one of the following values:
 ## 
 ## @table @asis
 ## @item 1
 ## Converged to a solution point. Relative residual error is less than specified
@@ -73,31 +80,32 @@ function [x, fvec, info, output, fjac] =
 
   xsiz = size (x0);
   n = numel (x0);
 
   has_jac = strcmpi (optimget (options, "Jacobian", "off"), "on");
   maxiter = optimget (options, "MaxIter", Inf);
   maxfev = optimget (options, "MaxFunEvals", Inf);
   outfcn = optimget (options, "OutputFcn");
-  pivoting = optimget (options, "Pivoting", false);
+  updating = optimget (options, "Updating", true);
+
   funvalchk = strcmpi (optimget (options, "FunValCheck", "off"), "on");
 
   if (funvalchk)
     ## Replace fun with a guarded version.
     fun = @(x) guarded_eval (fun, x);
   endif
 
   ## These defaults are rather stringent. I think that normally, user
   ## prefers accuracy to performance.
 
   macheps = eps (class (x0));
 
-  tolx = optimget (options, "TolX", 1e1*macheps);
-  tolf = optimget (options, "TolFun", 1e2*macheps);
+  tolx = optimget (options, "TolX", sqrt (macheps));
+  tolf = optimget (options, "TolFun", sqrt (macheps));
 
   factor = 100;
   ## FIXME: TypicalX corresponds to user scaling (???)
   autodg = true;
 
   niter = 1;
   nfev = 0;
 
@@ -116,97 +124,112 @@ function [x, fvec, info, output, fjac] =
       [fvec, fjac] = __fdjac__ (fcn, reshape (x, xsiz));
       nfev += 1 + length (x);
     endif
     fsiz = size (fvec);
     fvec = fvec(:);
     fn = norm (fvec);
     m = length (fvec);
     n = length (x);
-    if (m < n)
-      error ("fsolve:under", "cannot solve underdetermined systems");
-    elseif (m > n && niter == 1)
-      if (isempty (optimget (options, "TolFun")))
-	warning ("an overdetermined system cannot usually be solved exactly; consider specifying the TolFun option");
+
+    ## For square and overdetermined systems, we update a (pivoted) QR
+    ## factorization of the jacobian to avoid solving a full system in each
+    ## step. In this case, we pass a triangular matrix to __dogleg__.
+    ## Pivoted QR is used for slightly better robustness and invariance
+    ## w.r.t. permutations of variables.
+    useqr = updating && m >= n && n > 10;
+
+    if (useqr)
+      ## Get QR factorization of the jacobian, optionally with column pivoting.
+      ## TODO: pivoting is only done in the first step, to get invariance
+      ## w.r.t. permutations of variables. Maybe it could be beneficial to
+      ## repivot occassionally?
+      if (niter == 1)
+        [q, r, p] = qr (fjac, 0);
+        ## p is a column vector. Blame Matlab for the inconsistency.
+        ## Octave can handle permutation matrices gracefully.
+        p = eye (n)(:, p);
+      else
+        [q, r] = qr (fjac*p, 0);
       endif
     endif
-    
-    ## Get QR factorization of the jacobian.
-    if (pivoting)
-      [q, r, p] = qr (fjac);
-    else
-      [q, r] = qr (fjac);
-    endif
 
-    ## Get column norms, use them as scaling factor.
+    ## Get column norms, use them as scaling factors.
     jcn = norm (fjac, 'columns').';
     if (niter == 1)
       if (autodg)
         dg = jcn;
         dg(dg == 0) = 1;
       endif
       xn = norm (dg .* x);
-      delta = factor * xn;
+      ## FIXME: something better?
+      delta = max (factor * xn, 1);
     endif
 
     ## Rescale if necessary.
     if (autodg)
       dg = max (dg, jcn);
     endif
 
     nfail = 0;
     nsuc = 0;
     ## Inner loop.
     while (niter <= maxiter && nfev < maxfev && ! info)
 
-      qtf = q'*fvec;
+      if (useqr)
+        tr_mat = r;
+        tr_vec = q'*fvec;
+      else
+        tr_mat = fjac;
+        tr_vec = fvec;
+      endif
 
-      ## Get TR model (dogleg) minimizer
-      ## in case of an overdetermined system, get lsq solution.
-      s = - __dogleg__ (r(1:n,:), qtf(1:n), dg, delta);
-      if (pivoting)
-	s = p * s;
+      ## Get trust-region model (dogleg) minimizer.
+      if (useqr)
+        qtf = q'*fvec;
+        s = - __dogleg__ (r, qtf, dg, delta);
+        w = qtf + r * s;
+        s = p * s;
+      else
+        s = - __dogleg__ (fjac, fvec, dg, delta);
+        w = fvec + fjac * s;
       endif
+
       sn = norm (dg .* s);
-
       if (niter == 1)
         delta = min (delta, sn);
       endif
 
       fvec1 = fcn (reshape (x + s, xsiz)) (:);
       fn1 = norm (fvec1);
+      nfev ++;
 
       if (fn1 < fn)
         ## Scaled actual reduction.
         actred = 1 - (fn1/fn)^2;
       else
         actred = -1;
       endif
 
       ## Scaled predicted reduction, and ratio.
-      if (pivoting)
-	w = qtf + r*(p'*s);
-      else
-	w = qtf + r*s;
-      endif
       t = norm (w);
       if (t < fn)
         prered = 1 - (t/fn)^2;
         ratio = actred / prered;
       else
         prered = 0;
         ratio = 0;
       endif
 
       ## Update delta.
       if (ratio < 0.1)
         nsuc = 0;
         nfail ++;
         delta *= 0.5;
-        if (delta <= sqrt (macheps)*xn)
+        if (delta <= 1e1*macheps*xn)
           ## Trust region became uselessly small.
           info = -3;
           break;
         endif
       else
         nfail = 0;
         nsuc ++;
         if (abs (1-ratio) <= 0.1)
@@ -220,16 +243,30 @@ function [x, fvec, info, output, fjac] =
         ## Successful iteration.
         x += s;
         xn = norm (dg .* x);
         fvec = fvec1;
         fn = fn1;
         niter ++;
       endif
 
+      ## FIXME: should outputfcn be only called after a successful iteration?
+      if (outfcn)
+        optimvalues.iter = niter;
+        optimvalues.funccount = nfev;
+        optimvalues.fval = fn;
+        optimvalues.searchdirection = s;
+        state = 'iter';
+        stop = outfcn (x, optimvalues, state);
+        if (stop)
+          info = -1;
+          break;
+        endif
+      endif
+
       ## Tests for termination conditions. A mysterious place, anything
       ## can happen if you change something here...
       
       ## The rule of thumb (which I'm not sure M*b is quite following)
       ## is that for a tolerance that depends on scaling, only 0 makes
       ## sense as a default value. But 0 usually means uselessly long
       ## iterations, so we need scaling-independent tolerances wherever
       ## possible.
@@ -249,39 +286,44 @@ function [x, fvec, info, output, fjac] =
 	  ## for two different tests, but that's what M*b manual appears
 	  ## to say.
         elseif (actred < tolf)
           info = 3;
         endif
       endif
 
       ## Criterion for recalculating jacobian.
-      if (nfail == 2)
+      if (! updating || nfail == 2)
         break;
       endif
 
       ## Compute the scaled Broyden update.
-      u = (fvec1 - q*w) / sn; 
-      v = dg .* ((dg .* s) / sn);
-      if (pivoting)
-	v = p'*v;
+      if (useqr)
+        u = (fvec1 - q*w) / sn; 
+        v = dg .* ((dg .* s) / sn);
+        v = p' * v;
+
+        ## Update the QR factorization.
+        [q, r] = qrupdate (q, r, u, v);
+      else
+        u = (fvec1 - w);
+        v = dg .* ((dg .* s) / sn);
+
+        ## update the jacobian
+        fjac += u * v';
       endif
-
-      ## Update the QR factorization.
-      [q, r] = qrupdate (q, r, u, v);
-
     endwhile
   endwhile
 
   ## Restore original shapes.
   x = reshape (x, xsiz);
   fvec = reshape (fvec, fsiz);
 
   output.iterations = niter;
-  output.funcCount = niter + 2;
+  output.funcCount = nfev;
 
 endfunction
 
 ## An assistant function that evaluates a function handle and checks for
 ## bad results.
 function fx = guarded_eval (fun, x)
   fx = fun (x);
   if (! all (isreal (fx)))
@@ -336,17 +378,17 @@ endfunction
 %!  retval(2) = 3*x + 2**y -z**3 + 1;
 %!  retval(3) = x + y + z - 5;
 %!  retval(4) = x*x + y - z*log(z) - 1.36;
 %!test
 %! x_opt = [ 0.599054;
 %! 2.395931;
 %! 2.005014 ];
 %! tol = 1.0e-5;
-%! [x, fval, info] = fsolve (@f, [ 0.5; 2.0; 2.5 ], optimset ("TolFun", 1e-6));
+%! [x, fval, info] = fsolve (@f, [ 0.5; 2.0; 2.5 ]);
 %! assert (info > 0);
 %! assert (norm (x - x_opt, Inf) < tol);
 %! assert (norm (fval) < tol);
 
 %!function retval = f (p) 
 %!  x = p(1);
 %!  y = p(2);
 %!  z = p(3);
@@ -354,13 +396,28 @@ endfunction
 %!  retval(1) = sin(x) + y**2 + log(z) - 7;
 %!  retval(2) = 3*x + 2**y -z**3 + 1;
 %!  retval(3) = x + y + z - 5;
 %!test
 %! x_opt = [ 0.599054;
 %! 2.395931;
 %! 2.005014 ];
 %! tol = 1.0e-5;
-%! opt = optimset ("Pivoting", true);
+%! opt = optimset ("Updating", "qrp");
 %! [x, fval, info] = fsolve (@f, [ 0.5; 2.0; 2.5 ], opt);
 %! assert (info > 0);
 %! assert (norm (x - x_opt, Inf) < tol);
 %! assert (norm (fval) < tol);
+
+%!test
+%! b0 = 3;
+%! a0 = 0.2;
+%! x = 0:.5:5;
+%! noise = 1e-5 * sin (100*x);
+%! y = exp (-a0*x) + b0 + noise;
+%! c_opt = [a0, b0];
+%! tol = 1e-5;
+%! 
+%! [c, fval, info, output] =  fsolve (@(c) (exp(-c(1)*x) + c(2) - y), [0, 0]);
+%! assert (info > 0);
+%! assert (norm (c - c_opt, Inf) < tol);
+%! assert (norm (fval) < norm (noise));
+
