# HG changeset patch
# User Rik <rik@octave.org>
# Date 1386223998 28800
#      Wed Dec 04 22:13:18 2013 -0800
# Node ID 8e056300994bd0cc8aaf3da435c806cb6346fc39
# Parent  938f0133904329073b558294303380909c36b920
Follow coding convention of defining and initializing only 1 variable per line in liboctave.

* liboctave/array/Array-b.cc, liboctave/array/Array-util.cc,
liboctave/array/Array.cc, liboctave/array/CDiagMatrix.cc,
liboctave/array/CMatrix.cc, liboctave/array/CSparse.cc,
liboctave/array/MDiagArray2.cc, liboctave/array/MatrixType.cc,
liboctave/array/PermMatrix.cc, liboctave/array/Sparse.cc,
liboctave/array/Sparse.h, liboctave/array/boolSparse.cc,
liboctave/array/dDiagMatrix.cc, liboctave/array/dMatrix.cc,
liboctave/array/dSparse.cc, liboctave/array/dim-vector.cc,
liboctave/array/fCDiagMatrix.cc, liboctave/array/fCMatrix.cc,
liboctave/array/fDiagMatrix.cc, liboctave/array/fMatrix.cc,
liboctave/array/idx-vector.cc, liboctave/array/idx-vector.h,
liboctave/numeric/CmplxLU.cc, liboctave/numeric/CmplxQR.cc,
liboctave/numeric/base-qr.cc, liboctave/numeric/bsxfun-defs.cc,
liboctave/numeric/bsxfun.h, liboctave/numeric/dbleLU.cc,
liboctave/numeric/dbleQR.cc, liboctave/numeric/fCmplxLU.cc,
liboctave/numeric/fCmplxQR.cc, liboctave/numeric/floatLU.cc,
liboctave/numeric/floatQR.cc, liboctave/numeric/lo-specfun.cc,
liboctave/numeric/oct-convn.cc, liboctave/numeric/oct-norm.cc,
liboctave/numeric/sparse-dmsolve.cc, liboctave/operators/mx-inlines.cc,
liboctave/operators/mx-op-defs.h, liboctave/util/caseless-str.h,
liboctave/util/kpse.cc, liboctave/util/lo-utils.cc,
liboctave/util/oct-binmap.h, liboctave/util/oct-cmplx.h,
liboctave/util/oct-inttypes.cc, liboctave/util/oct-inttypes.h,
liboctave/util/oct-sort.cc:
Follow coding convention of defining and initializing only 1 variable per line in liboctave.

diff --git a/liboctave/array/Array-b.cc b/liboctave/array/Array-b.cc
--- a/liboctave/array/Array-b.cc
+++ b/liboctave/array/Array-b.cc
@@ -47,17 +47,18 @@ static void do_bool_partition (bool *dat
 
 template<bool desc>
 static void do_bool_partition (bool *data, octave_idx_type *idx,
                                octave_idx_type nel)
 {
   // FIXME: This is essentially a simple bucket sort.
   // Can it be efficiently done by std::partition?
   OCTAVE_LOCAL_BUFFER (octave_idx_type, jdx, nel);
-  octave_idx_type k = 0, l = 0;
+  octave_idx_type k = 0;
+  octave_idx_type l = 0;
   for (octave_idx_type i = 0; i < nel; i++)
     {
       if (data[i] == desc)
         {
           data[k] = desc;
           idx[k++] = idx[i];
         }
       else
diff --git a/liboctave/array/Array-util.cc b/liboctave/array/Array-util.cc
--- a/liboctave/array/Array-util.cc
+++ b/liboctave/array/Array-util.cc
@@ -418,19 +418,21 @@ get_ra_idx (octave_idx_type idx, const d
 #endif
 
   return retval;
 }
 
 dim_vector
 zero_dims_inquire (const Array<idx_vector>& ia, const dim_vector& rhdv)
 {
-  int ial = ia.length (), rhdvl = rhdv.length ();
+  int ial = ia.length ();
+  int rhdvl = rhdv.length ();
   dim_vector rdv = dim_vector::alloc (ial);
-  bool *scalar = new bool [ial], *colon = new bool [ial];
+  bool *scalar = new bool [ial];
+  bool *colon = new bool [ial];
   // Mark scalars and colons, count non-scalar indices.
   int nonsc = 0;
   bool all_colons = true;
   for (int i = 0; i < ial; i++)
     {
       // FIXME: should we check for length() instead?
       scalar[i] = ia(i).is_scalar ();
       colon[i] = ia(i).is_colon ();
@@ -474,17 +476,18 @@ zero_dims_inquire (const Array<idx_vecto
 
   return rdv;
 }
 
 dim_vector
 zero_dims_inquire (const idx_vector& i, const idx_vector& j,
                    const dim_vector& rhdv)
 {
-  bool icol = i.is_colon (), jcol = j.is_colon ();
+  bool icol = i.is_colon ();
+  bool jcol = j.is_colon ();
   dim_vector rdv;
   if (icol && jcol && rhdv.length () == 2)
     {
       rdv(0) = rhdv(0);
       rdv(1) = rhdv(1);
     }
   else if (rhdv.length () == 2
            && ! i.is_scalar () && ! j.is_scalar ())
@@ -558,20 +561,22 @@ sub2ind (const dim_vector& dv, const Arr
           octave_idx_type idx = idxa(len-1)(0);
           for (octave_idx_type i = len - 2; i >= 0; i--)
             idx = idx * dvx(i) + idxa(i)(0);
           retval = idx_vector (idx);
         }
       else if (all_ranges && clen != 0)
         {
           // All ranges case - the result is a range.
-          octave_idx_type start = 0, step = 0;
+          octave_idx_type start = 0;
+          octave_idx_type step = 0;
           for (octave_idx_type i = len - 1; i >= 0; i--)
             {
-              octave_idx_type xstart = idxa(i)(0), xstep = idxa(i)(1) - xstart;
+              octave_idx_type xstart = idxa(i)(0);
+              octave_idx_type xstep = idxa(i)(1) - xstart;
               start = start * dvx(i) + xstart;
               step = step * dvx(i) + xstep;
             }
           retval = idx_vector::make_range (start, step, clen);
         }
       else
         {
           Array<octave_idx_type> idx (idxa(0).orig_dimensions ());
@@ -592,17 +597,18 @@ sub2ind (const dim_vector& dv, const Arr
     current_liboctave_error_handler ("sub2ind: needs at least 2 indices");
 
   return retval;
 }
 
 Array<idx_vector>
 ind2sub (const dim_vector& dv, const idx_vector& idx)
 {
-  octave_idx_type len = idx.length (0), n = dv.length ();
+  octave_idx_type len = idx.length (0);
+  octave_idx_type n = dv.length ();
   Array<idx_vector> retval (dim_vector (n, 1));
   octave_idx_type numel = dv.numel ();
 
   if (idx.extent (numel) > numel)
     current_liboctave_error_handler ("ind2sub: index out of range");
   else
     {
       if (idx.is_scalar ())
diff --git a/liboctave/array/Array.cc b/liboctave/array/Array.cc
--- a/liboctave/array/Array.cc
+++ b/liboctave/array/Array.cc
@@ -265,17 +265,19 @@ Array<T>::column (octave_idx_type k) con
 
   return Array<T> (*this, dim_vector (r, 1), k*r, k*r + r);
 }
 
 template <class T>
 Array<T>
 Array<T>::page (octave_idx_type k) const
 {
-  octave_idx_type r = dimensions(0), c = dimensions (1), p = r*c;
+  octave_idx_type r = dimensions(0);
+  octave_idx_type c = dimensions(1);
+  octave_idx_type p = r*c;
 #ifdef BOUNDS_CHECKING
   if (k < 0 || k > dimensions.numel (2))
     gripe_index_out_of_range (3, 3, k+1, dimensions.numel (2));
 #endif
 
   return Array<T> (*this, dim_vector (r, c), k*p, k*p + p);
 }
 
@@ -388,17 +390,18 @@ public:
 private:
 
   // Recursive N-d generalized transpose
   template <class T>
   T *do_permute (const T *src, T *dest, int lev) const
   {
     if (lev == 0)
       {
-        octave_idx_type step = stride[0], len = dim[0];
+        octave_idx_type step = stride[0];
+        octave_idx_type len = dim[0];
         if (step == 1)
           {
             copy_or_memcpy (len, src, dest);
             dest += len;
           }
         else
           {
             for (octave_idx_type i = 0, j = 0; i < len; i++, j += step)
@@ -406,17 +409,18 @@ private:
 
             dest += len;
           }
       }
     else if (use_blk && lev == 1)
       dest = blk_trans (src, dest, dim[1], dim[0]);
     else
       {
-        octave_idx_type step = stride[lev], len = dim[lev];
+        octave_idx_type step = stride[lev];
+        octave_idx_type len = dim[lev];
         for (octave_idx_type i = 0, j = 0; i < len; i++, j+= step)
           dest = do_permute (src + i * step, dest, lev-1);
       }
 
     return dest;
   }
 
   // No copying!
@@ -563,49 +567,52 @@ private:
   // Recursive N-d indexing
   template <class T>
   T *do_index (const T *src, T *dest, int lev) const
   {
     if (lev == 0)
       dest += idx[0].index (src, dim[0], dest);
     else
       {
-        octave_idx_type nn = idx[lev].length (dim[lev]), d = cdim[lev];
+        octave_idx_type nn = idx[lev].length (dim[lev]);
+        octave_idx_type d = cdim[lev];
         for (octave_idx_type i = 0; i < nn; i++)
           dest = do_index (src + d*idx[lev].xelem (i), dest, lev-1);
       }
 
     return dest;
   }
 
   // Recursive N-d indexed assignment
   template <class T>
   const T *do_assign (const T *src, T *dest, int lev) const
   {
     if (lev == 0)
       src += idx[0].assign (src, dim[0], dest);
     else
       {
-        octave_idx_type nn = idx[lev].length (dim[lev]), d = cdim[lev];
+        octave_idx_type nn = idx[lev].length (dim[lev]);
+        octave_idx_type d = cdim[lev];
         for (octave_idx_type i = 0; i < nn; i++)
           src = do_assign (src, dest + d*idx[lev].xelem (i), lev-1);
       }
 
     return src;
   }
 
   // Recursive N-d indexed assignment
   template <class T>
   void do_fill (const T& val, T *dest, int lev) const
   {
     if (lev == 0)
       idx[0].fill (val, dim[0], dest);
     else
       {
-        octave_idx_type nn = idx[lev].length (dim[lev]), d = cdim[lev];
+        octave_idx_type nn = idx[lev].length (dim[lev]);
+        octave_idx_type d = cdim[lev];
         for (octave_idx_type i = 0; i < nn; i++)
           do_fill (val, dest + d*idx[lev].xelem (i), lev-1);
       }
   }
 
   // No copying!
 
   rec_index_helper (const rec_index_helper&);
@@ -650,17 +657,18 @@ public:
     int i = 0;
     for (; i < l-1 && ndv(i) == odv(i); i++) ld *= ndv(i);
     n = l - i;
     cext = new octave_idx_type [3*n];
     // Trick to avoid three allocations
     sext = cext + n;
     dext = sext + n;
 
-    octave_idx_type sld = ld, dld = ld;
+    octave_idx_type sld = ld;
+    octave_idx_type dld = ld;
     for (int j = 0; j < n; j++)
       {
         cext[j] = std::min (ndv(i+j), odv(i+j));
         sext[j] = sld *= odv(i+j);
         dext[j] = dld *= ndv(i+j);
       }
     cext[0] *= ld;
   }
@@ -675,17 +683,19 @@ private:
   {
     if (lev == 0)
       {
         copy_or_memcpy (cext[0], src, dest);
         fill_or_memset (dext[0] - cext[0], rfv, dest + cext[0]);
       }
     else
       {
-        octave_idx_type sd = sext[lev-1], dd = dext[lev-1], k;
+        octave_idx_type sd = sext[lev-1];
+        octave_idx_type dd = dext[lev-1];
+        octave_idx_type k;
         for (k = 0; k < cext[lev]; k++)
           do_resize_fill (src + k * sd, dest + k * dd, rfv, lev - 1);
 
         fill_or_memset (dext[lev] - k * dd, rfv, dest + k * dd);
       }
   }
 
   // No copying!
@@ -766,32 +776,35 @@ Array<T>::index (const idx_vector& i) co
 }
 
 template <class T>
 Array<T>
 Array<T>::index (const idx_vector& i, const idx_vector& j) const
 {
   // Get dimensions, allowing Fortran indexing in the 2nd dim.
   dim_vector dv = dimensions.redim (2);
-  octave_idx_type r = dv(0), c = dv(1);
+  octave_idx_type r = dv(0);
+  octave_idx_type c = dv(1);
   Array<T> retval;
 
   if (i.is_colon () && j.is_colon ())
     {
       // A(:,:) produces a shallow copy.
       retval = Array<T> (*this, dv);
     }
   else
     {
       if (i.extent (r) != r)
         gripe_index_out_of_range (2, 1, i.extent (r), r); // throws
       if (j.extent (c) != c)
         gripe_index_out_of_range (2, 2, j.extent (c), c); // throws
 
-      octave_idx_type n = numel (), il = i.length (r), jl = j.length (c);
+      octave_idx_type n = numel ();
+      octave_idx_type il = i.length (r);
+      octave_idx_type jl = j.length (c);
 
       idx_vector ii (i);
 
       if (ii.maybe_reduce (r, j, c))
         {
           octave_idx_type l, u;
           if (ii.length () > 0 && ii.is_cont_range (n, l, u))
             // If suitable, produce a shallow slice.
@@ -952,17 +965,18 @@ Array<T>::resize1 (octave_idx_type n, co
                   *this = tmp;
                 }
             }
           else if (n != nx)
             {
               Array<T> tmp = Array<T> (dv);
               T *dest = tmp.fortran_vec ();
 
-              octave_idx_type n0 = std::min (n, nx), n1 = n - n0;
+              octave_idx_type n0 = std::min (n, nx);
+              octave_idx_type n1 = n - n0;
               copy_or_memcpy (n0, data (), dest);
               fill_or_memset (n1, rfv, dest + n0);
 
               *this = tmp;
             }
         }
     }
   else
@@ -970,24 +984,27 @@ Array<T>::resize1 (octave_idx_type n, co
 }
 
 template <class T>
 void
 Array<T>::resize2 (octave_idx_type r, octave_idx_type c, const T& rfv)
 {
   if (r >= 0 && c >= 0 && ndims () == 2)
     {
-      octave_idx_type rx = rows (), cx = columns ();
+      octave_idx_type rx = rows ();
+      octave_idx_type cx = columns ();
       if (r != rx || c != cx)
         {
           Array<T> tmp = Array<T> (dim_vector (r, c));
           T *dest = tmp.fortran_vec ();
 
-          octave_idx_type r0 = std::min (r, rx), r1 = r - r0;
-          octave_idx_type c0 = std::min (c, cx), c1 = c - c0;
+          octave_idx_type r0 = std::min (r, rx);
+          octave_idx_type r1 = r - r0;
+          octave_idx_type c0 = std::min (c, cx);
+          octave_idx_type c1 = c - c0;
           const T *src = data ();
           if (r == rx)
             {
               copy_or_memcpy (r * c0, src, dest);
               dest += r * c0;
             }
           else
             {
@@ -1037,17 +1054,18 @@ Array<T>::resize (const dim_vector& dv, 
 
 template <class T>
 Array<T>
 Array<T>::index (const idx_vector& i, bool resize_ok, const T& rfv) const
 {
   Array<T> tmp = *this;
   if (resize_ok)
     {
-      octave_idx_type n = numel (), nx = i.extent (n);
+      octave_idx_type n = numel ();
+      octave_idx_type nx = i.extent (n);
       if (n != nx)
         {
           if (i.is_scalar ())
             return Array<T> (dim_vector (1, 1), rfv);
           else
             tmp.resize1 (nx, rfv);
         }
 
@@ -1062,18 +1080,20 @@ template <class T>
 Array<T>
 Array<T>::index (const idx_vector& i, const idx_vector& j,
                  bool resize_ok, const T& rfv) const
 {
   Array<T> tmp = *this;
   if (resize_ok)
     {
       dim_vector dv = dimensions.redim (2);
-      octave_idx_type r = dv(0), c = dv(1);
-      octave_idx_type rx = i.extent (r), cx = j.extent (c);
+      octave_idx_type r = dv(0);
+      octave_idx_type c = dv(1);
+      octave_idx_type rx = i.extent (r);
+      octave_idx_type cx = j.extent (c);
       if (r != rx || c != cx)
         {
           if (i.is_scalar () && j.is_scalar ())
             return Array<T> (dim_vector (1, 1), rfv);
           else
             tmp.resize2 (rx, cx, rfv);
         }
 
@@ -1114,17 +1134,18 @@ Array<T>::index (const Array<idx_vector>
   return tmp.index (ia);
 }
 
 
 template <class T>
 void
 Array<T>::assign (const idx_vector& i, const Array<T>& rhs, const T& rfv)
 {
-  octave_idx_type n = numel (), rhl = rhs.numel ();
+  octave_idx_type n = numel ();
+  octave_idx_type rhl = rhs.numel ();
 
   if (rhl == 1 || i.length (n) == rhl)
     {
       octave_idx_type nx = i.extent (n);
       bool colon = i.is_colon_equiv (nx);
       // Try to resize first if necessary.
       if (nx != n)
         {
@@ -1185,17 +1206,18 @@ Array<T>::assign (const idx_vector& i, c
     rdv = zero_dims_inquire (i, j, rhdv);
   else
     {
       rdv(0) = i.extent (dv(0));
       rdv(1) = j.extent (dv(1));
     }
 
   bool isfill = rhs.numel () == 1;
-  octave_idx_type il = i.length (rdv(0)), jl = j.length (rdv(1));
+  octave_idx_type il = i.length (rdv(0));
+  octave_idx_type jl = j.length (rdv(1));
   rhdv.chop_all_singletons ();
   bool match = (isfill
                 || (rhdv.length () == 2 && il == rhdv(0) && jl == rhdv(1)));
   match = match || (il == 1 && jl == rhdv(0) && rhdv(1) == 1);
 
   if (match)
     {
       bool all_colons = (i.is_colon_equiv (rdv(0))
@@ -1223,17 +1245,19 @@ Array<T>::assign (const idx_vector& i, c
           if (isfill)
             fill (rhs(0));
           else
             *this = rhs.reshape (dimensions);
         }
       else
         {
           // The actual work.
-          octave_idx_type n = numel (), r = dv (0), c = dv (1);
+          octave_idx_type n = numel ();
+          octave_idx_type r = dv(0);
+          octave_idx_type c = dv(1);
           idx_vector ii (i);
 
           const T* src = rhs.data ();
           T *dest = fortran_vec ();
 
           // Try reduction first.
           if (ii.maybe_reduce (r, j, c))
             {
@@ -1294,20 +1318,23 @@ Array<T>::assign (const Array<idx_vector
       else
         {
           rdv = dim_vector::alloc (ial);
           for (int i = 0; i < ial; i++)
             rdv(i) = ia(i).extent (dv(i));
         }
 
       // Check whether LHS and RHS match, up to singleton dims.
-      bool match = true, all_colons = true, isfill = rhs.numel () == 1;
+      bool match = true;
+      bool all_colons = true;
+      bool isfill = rhs.numel () == 1;
 
       rhdv.chop_all_singletons ();
-      int j = 0, rhdvl = rhdv.length ();
+      int j = 0;
+      int rhdvl = rhdv.length ();
       for (int i = 0; i < ial; i++)
         {
           all_colons = all_colons && ia(i).is_colon_equiv (rdv(i));
           octave_idx_type l = ia(i).length (rdv(i));
           if (l == 1) continue;
           match = match && j < rhdvl && l == rhdv(j++);
         }
 
@@ -1422,17 +1449,19 @@ Array<T>::delete_elements (int dim, cons
       if (i.extent (n) != n)
         gripe_del_index_out_of_range (false, i.extent (n), n);
 
       octave_idx_type l, u;
 
       if (i.is_cont_range (n, l, u))
         {
           // Special case deleting a contiguous range.
-          octave_idx_type nd = n + l - u, dl = 1, du = 1;
+          octave_idx_type nd = n + l - u;
+          octave_idx_type dl = 1;
+          octave_idx_type du = 1;
           dim_vector rdv = dimensions;
           rdv(dim) = nd;
           for (int k = 0; k < dim; k++) dl *= dimensions(k);
           for (int k = dim + 1; k < ndims (); k++) du *= dimensions(k);
 
           // Special case deleting a contiguous range.
           Array<T> tmp = Array<T> (rdv);
           const T *src = data ();
@@ -1771,17 +1800,18 @@ Array<T>::sort (int dim, sortmode mode) 
     return m;
 
   if (stride == 1)
     {
       for (octave_idx_type j = 0; j < iter; j++)
         {
           // copy and partition out NaNs.
           // FIXME: impact on integer types noticeable?
-          octave_idx_type kl = 0, ku = ns;
+          octave_idx_type kl = 0;
+          octave_idx_type ku = ns;
           for (octave_idx_type i = 0; i < ns; i++)
             {
               T tmp = ov[i];
               if (sort_isnan<T> (tmp))
                 v[--ku] = tmp;
               else
                 v[kl++] = tmp;
             }
@@ -1815,17 +1845,18 @@ Array<T>::sort (int dim, sortmode mode) 
               offset -= stride;
               offset2++;
             }
 
           offset += offset2 * stride * ns;
 
           // gather and partition out NaNs.
           // FIXME: impact on integer types noticeable?
-          octave_idx_type kl = 0, ku = ns;
+          octave_idx_type kl = 0;
+          octave_idx_type ku = ns;
           for (octave_idx_type i = 0; i < ns; i++)
             {
               T tmp = ov[i*stride + offset];
               if (sort_isnan<T> (tmp))
                 buf[--ku] = tmp;
               else
                 buf[kl++] = tmp;
             }
@@ -1893,17 +1924,18 @@ Array<T>::sort (Array<octave_idx_type> &
     return m;
 
   if (stride == 1)
     {
       for (octave_idx_type j = 0; j < iter; j++)
         {
           // copy and partition out NaNs.
           // FIXME: impact on integer types noticeable?
-          octave_idx_type kl = 0, ku = ns;
+          octave_idx_type kl = 0;
+          octave_idx_type ku = ns;
           for (octave_idx_type i = 0; i < ns; i++)
             {
               T tmp = ov[i];
               if (sort_isnan<T> (tmp))
                 {
                   --ku;
                   v[ku] = tmp;
                   vi[ku] = i;
@@ -1951,17 +1983,18 @@ Array<T>::sort (Array<octave_idx_type> &
               offset -= stride;
               offset2++;
             }
 
           offset += offset2 * stride * ns;
 
           // gather and partition out NaNs.
           // FIXME: impact on integer types noticeable?
-          octave_idx_type kl = 0, ku = ns;
+          octave_idx_type kl = 0;
+          octave_idx_type ku = ns;
           for (octave_idx_type i = 0; i < ns; i++)
             {
               T tmp = ov[i*stride + offset];
               if (sort_isnan<T> (tmp))
                 {
                   --ku;
                   buf[ku] = tmp;
                   bufi[ku] = i;
@@ -2051,47 +2084,50 @@ Array<T>::is_sorted (sortmode mode) cons
 template <class T>
 Array<octave_idx_type>
 Array<T>::sort_rows_idx (sortmode mode) const
 {
   Array<octave_idx_type> idx;
 
   octave_sort<T> lsort (safe_comparator (mode, *this, true));
 
-  octave_idx_type r = rows (), c = cols ();
+  octave_idx_type r = rows ();
+  octave_idx_type c = cols ();
 
   idx = Array<octave_idx_type> (dim_vector (r, 1));
 
   lsort.sort_rows (data (), idx.fortran_vec (), r, c);
 
   return idx;
 }
 
 
 template <class T>
 sortmode
 Array<T>::is_sorted_rows (sortmode mode) const
 {
   octave_sort<T> lsort;
 
-  octave_idx_type r = rows (), c = cols ();
+  octave_idx_type r = rows ();
+  octave_idx_type c = cols ();
 
   if (r <= 1 || c == 0)
     return mode ? mode : ASCENDING;
 
   if (mode == UNSORTED)
     {
       // Auto-detect mode.
       compare_fcn_type compare
         = safe_comparator (ASCENDING, *this, false);
 
       octave_idx_type i;
       for (i = 0; i < cols (); i++)
         {
-          T l = elem (0, i), u = elem (rows () - 1, i);
+          T l = elem (0, i);
+          T u = elem (rows () - 1, i);
           if (compare (l, u))
             {
               if (mode == DESCENDING)
                 {
                   mode = UNSORTED;
                   break;
                 }
               else
@@ -2145,17 +2181,18 @@ Array<T>::lookup (const T& value, sortmo
 
   return lsort.lookup (data (), n, value);
 }
 
 template <class T>
 Array<octave_idx_type>
 Array<T>::lookup (const Array<T>& values, sortmode mode) const
 {
-  octave_idx_type n = numel (), nval = values.numel ();
+  octave_idx_type n = numel ();
+  octave_idx_type nval = values.numel ();
   octave_sort<T> lsort;
   Array<octave_idx_type> idx (values.dims ());
 
   if (mode == UNSORTED)
     {
       // auto-detect mode
       if (n > 1 && lsort.descending_compare (elem (0), elem (n-1)))
         mode = DESCENDING;
@@ -2189,17 +2226,18 @@ Array<T>::lookup (const Array<T>& values
   return idx;
 }
 
 template <class T>
 octave_idx_type
 Array<T>::nnz (void) const
 {
   const T *src = data ();
-  octave_idx_type nel = nelem (), retval = 0;
+  octave_idx_type nel = nelem ();
+  octave_idx_type retval = 0;
   const T zero = T ();
   for (octave_idx_type i = 0; i < nel; i++)
     if (src[i] != zero)
       retval++;
 
   return retval;
 }
 
@@ -2228,34 +2266,36 @@ Array<T>::find (octave_idx_type n, bool 
     {
       // We want a fixed max number of elements, usually small. So be
       // optimistic, alloc the array in advance, and then resize if
       // needed.
       retval.clear (n, 1);
       if (backward)
         {
           // Do the search as a series of successive single-element searches.
-          octave_idx_type k = 0, l = nel - 1;
+          octave_idx_type k = 0;
+          octave_idx_type l = nel - 1;
           for (; k < n; k++)
             {
               for (; l >= 0 && src[l] == zero; l--) ;
               if (l >= 0)
                 retval(k) = l--;
               else
                 break;
             }
           if (k < n)
             retval.resize2 (k, 1);
           octave_idx_type *rdata = retval.fortran_vec ();
           std::reverse (rdata, rdata + k);
         }
       else
         {
           // Do the search as a series of successive single-element searches.
-          octave_idx_type k = 0, l = 0;
+          octave_idx_type k = 0;
+          octave_idx_type l = 0;
           for (; k < n; k++)
             {
               for (; l != nel && src[l] == zero; l++) ;
               if (l != nel)
                 retval(k) = l++;
               else
                 break;
             }
@@ -2364,17 +2404,18 @@ Array<T>::nth_element (const idx_vector&
 
   OCTAVE_LOCAL_BUFFER (T, buf, ns);
 
   octave_sort<T> lsort;
   lsort.set_compare (mode);
 
   for (octave_idx_type j = 0; j < iter; j++)
     {
-      octave_idx_type kl = 0, ku = ns;
+      octave_idx_type kl = 0;
+      octave_idx_type ku = ns;
 
       if (stride == 1)
         {
           // copy without NaNs.
           // FIXME: impact on integer types noticeable?
           for (octave_idx_type i = 0; i < ns; i++)
             {
               T tmp = ov[i];
diff --git a/liboctave/array/CDiagMatrix.cc b/liboctave/array/CDiagMatrix.cc
--- a/liboctave/array/CDiagMatrix.cc
+++ b/liboctave/array/CDiagMatrix.cc
@@ -443,17 +443,18 @@ operator * (const ComplexDiagMatrix& a, 
   octave_idx_type b_nr = b.rows ();
   octave_idx_type b_nc = b.cols ();
 
   if (a_nc != b_nr)
     gripe_nonconformant ("operator *", a_nr, a_nc, b_nr, b_nc);
 
   ComplexDiagMatrix c (a_nr, b_nc);
 
-  octave_idx_type len = c.length (), lenm = len < a_nc ? len : a_nc;
+  octave_idx_type len = c.length ();
+  octave_idx_type lenm = len < a_nc ? len : a_nc;
 
   for (octave_idx_type i = 0; i < lenm; i++)
     c.dgxelem (i) = a.dgelem (i) * b.dgelem (i);
   for (octave_idx_type i = lenm; i < len; i++)
     c.dgxelem (i) = 0.0;
 
   return c;
 }
@@ -544,17 +545,18 @@ ComplexDiagMatrix::determinant (void) co
 
   return det;
 }
 
 double
 ComplexDiagMatrix::rcond (void) const
 {
   ColumnVector av = extract_diag (0).map<double> (std::abs);
-  double amx = av.max (), amn = av.min ();
+  double amx = av.max ();
+  double amn = av.min ();
   return amx == 0 ? 0.0 : amn / amx;
 }
 
 // i/o
 
 std::ostream&
 operator << (std::ostream& os, const ComplexDiagMatrix& a)
 {
diff --git a/liboctave/array/CMatrix.cc b/liboctave/array/CMatrix.cc
--- a/liboctave/array/CMatrix.cc
+++ b/liboctave/array/CMatrix.cc
@@ -3766,18 +3766,20 @@ get_blas_trans_arg (bool trans, bool con
 // the general GEMM operation
 
 ComplexMatrix
 xgemm (const ComplexMatrix& a, const ComplexMatrix& b,
        blas_trans_type transa, blas_trans_type transb)
 {
   ComplexMatrix retval;
 
-  bool tra = transa != blas_no_trans, trb = transb != blas_no_trans;
-  bool cja = transa == blas_conj_trans, cjb = transb == blas_conj_trans;
+  bool tra = transa != blas_no_trans;
+  bool trb = transb != blas_no_trans;
+  bool cja = transa == blas_conj_trans;
+  bool cjb = transb == blas_conj_trans;
 
   octave_idx_type a_nr = tra ? a.cols () : a.rows ();
   octave_idx_type a_nc = tra ? a.rows () : a.cols ();
 
   octave_idx_type b_nr = trb ? b.cols () : b.rows ();
   octave_idx_type b_nc = trb ? b.rows () : b.cols ();
 
   if (a_nc != b_nr)
@@ -3823,18 +3825,20 @@ xgemm (const ComplexMatrix& a, const Com
                 for (octave_idx_type i = 0; i < j; i++)
                   retval.xelem (j,i) = retval.xelem (i,j);
 
             }
 
         }
       else
         {
-          octave_idx_type lda = a.rows (), tda = a.cols ();
-          octave_idx_type ldb = b.rows (), tdb = b.cols ();
+          octave_idx_type lda = a.rows ();
+          octave_idx_type tda = a.cols ();
+          octave_idx_type ldb = b.rows ();
+          octave_idx_type tdb = b.cols ();
 
           retval = ComplexMatrix (a_nr, b_nc, 0.0);
           Complex *c = retval.fortran_vec ();
 
           if (b_nc == 1 && a_nr == 1)
             {
               if (cja == cjb)
                 {
diff --git a/liboctave/array/CSparse.cc b/liboctave/array/CSparse.cc
--- a/liboctave/array/CSparse.cc
+++ b/liboctave/array/CSparse.cc
@@ -155,17 +155,18 @@ SparseComplexMatrix::SparseComplexMatrix
       data (i) = Complex (a.data (i));
       ridx (i) = a.ridx (i);
     }
 }
 
 SparseComplexMatrix::SparseComplexMatrix (const ComplexDiagMatrix& a)
   : MSparse<Complex> (a.rows (), a.cols (), a.length ())
 {
-  octave_idx_type j = 0, l = a.length ();
+  octave_idx_type j = 0;
+  octave_idx_type l = a.length ();
   for (octave_idx_type i = 0; i < l; i++)
     {
       cidx (i) = j;
       if (a(i, i) != 0.0)
         {
           data (j) = a(i, i);
           ridx (j) = i;
           j++;
@@ -772,17 +773,18 @@ SparseComplexMatrix::dinverse (MatrixTyp
           else
             retval = *this;
 
           // Force make_unique to be called
           Complex *v = retval.data ();
 
           if (calccond)
             {
-              double dmax = 0., dmin = octave_Inf;
+              double dmax = 0.;
+              double dmin = octave_Inf;
               for (octave_idx_type i = 0; i < nr; i++)
                 {
                   double tmp = std::abs (v[i]);
                   if (tmp > dmax)
                     dmax = tmp;
                   if (tmp < dmin)
                     dmin = tmp;
                 }
@@ -1316,17 +1318,18 @@ SparseComplexMatrix::dsolve (MatrixType 
           else
             for (octave_idx_type j = 0; j < b.cols (); j++)
               for (octave_idx_type k = 0; k < nc; k++)
                 for (octave_idx_type i = cidx (k); i < cidx (k+1); i++)
                   retval(k,j) = b(ridx (i),j) / data (i);
 
           if (calc_cond)
             {
-              double dmax = 0., dmin = octave_Inf;
+              double dmax = 0.;
+              double dmin = octave_Inf;
               for (octave_idx_type i = 0; i < nm; i++)
                 {
                   double tmp = std::abs (data (i));
                   if (tmp > dmax)
                     dmax = tmp;
                   if (tmp < dmin)
                     dmin = tmp;
                 }
@@ -1407,17 +1410,18 @@ SparseComplexMatrix::dsolve (MatrixType 
                           retval.xdata (ii++) = b.data (k) / data (i);
                         }
                     }
                 retval.xcidx (j+1) = ii;
               }
 
           if (calc_cond)
             {
-              double dmax = 0., dmin = octave_Inf;
+              double dmax = 0.;
+              double dmin = octave_Inf;
               for (octave_idx_type i = 0; i < nm; i++)
                 {
                   double tmp = std::abs (data (i));
                   if (tmp > dmax)
                     dmax = tmp;
                   if (tmp < dmin)
                     dmin = tmp;
                 }
@@ -1468,17 +1472,18 @@ SparseComplexMatrix::dsolve (MatrixType 
           else
             for (octave_idx_type j = 0; j < b.cols (); j++)
               for (octave_idx_type k = 0; k < nc; k++)
                 for (octave_idx_type i = cidx (k); i < cidx (k+1); i++)
                   retval(k,j) = b(ridx (i),j) / data (i);
 
           if (calc_cond)
             {
-              double dmax = 0., dmin = octave_Inf;
+              double dmax = 0.;
+              double dmin = octave_Inf;
               for (octave_idx_type i = 0; i < nr; i++)
                 {
                   double tmp = std::abs (data (i));
                   if (tmp > dmax)
                     dmax = tmp;
                   if (tmp < dmin)
                     dmin = tmp;
                 }
@@ -1559,17 +1564,18 @@ SparseComplexMatrix::dsolve (MatrixType 
                           retval.xdata (ii++) = b.data (k) / data (i);
                         }
                     }
                 retval.xcidx (j+1) = ii;
               }
 
           if (calc_cond)
             {
-              double dmax = 0., dmin = octave_Inf;
+              double dmax = 0.;
+              double dmin = octave_Inf;
               for (octave_idx_type i = 0; i < nm; i++)
                 {
                   double tmp = std::abs (data (i));
                   if (tmp > dmax)
                     dmax = tmp;
                   if (tmp < dmin)
                     dmin = tmp;
                 }
diff --git a/liboctave/array/MDiagArray2.cc b/liboctave/array/MDiagArray2.cc
--- a/liboctave/array/MDiagArray2.cc
+++ b/liboctave/array/MDiagArray2.cc
@@ -33,17 +33,18 @@ along with Octave; see the file COPYING.
 
 template <class T>
 bool
 MDiagArray2<T>::is_multiple_of_identity (T val) const
 {
   bool retval = this->rows () == this->cols ();
   if (retval)
     {
-      octave_idx_type len = this->length (), i = 0;
+      octave_idx_type len = this->length ();
+      octave_idx_type i = 0;
       for (; i < len; i++)
         if (DiagArray2<T>::elem (i, i) != val) break;
       retval = i == len;
     }
 
   return retval;
 }
 
diff --git a/liboctave/array/MatrixType.cc b/liboctave/array/MatrixType.cc
--- a/liboctave/array/MatrixType.cc
+++ b/liboctave/array/MatrixType.cc
@@ -86,17 +86,18 @@ matrix_real_probe (const MArray<T>& a)
           diag[j] = d;
         }
 
       for (octave_idx_type j = 0;
            j < ncols && (upper || lower || hermitian); j++)
         {
           for (octave_idx_type i = 0; i < j; i++)
             {
-              double aij = a.elem (i,j), aji = a.elem (j,i);
+              double aij = a.elem (i,j);
+              double aji = a.elem (j,i);
               lower = lower && (aij == zero);
               upper = upper && (aji == zero);
               hermitian = hermitian && (aij == aji
                                         && aij*aij < diag[i]*diag[j]);
             }
         }
 
       if (upper)
@@ -144,17 +145,18 @@ matrix_complex_probe (const MArray<std::
           diag[j] = d.real ();
         }
 
       for (octave_idx_type j = 0;
            j < ncols && (upper || lower || hermitian); j++)
         {
           for (octave_idx_type i = 0; i < j; i++)
             {
-              std::complex<T> aij = a.elem (i,j), aji = a.elem (j,i);
+              std::complex<T> aij = a.elem (i,j);
+              std::complex<T> aji = a.elem (j,i);
               lower = lower && (aij == zero);
               upper = upper && (aji == zero);
               hermitian = hermitian && (aij == std::conj (aji)
                                         && std::norm (aij) < diag[i]*diag[j]);
             }
         }
 
 
diff --git a/liboctave/array/PermMatrix.cc b/liboctave/array/PermMatrix.cc
--- a/liboctave/array/PermMatrix.cc
+++ b/liboctave/array/PermMatrix.cc
@@ -114,17 +114,18 @@ PermMatrix::determinant (void) const
       p[i] = pa[i];
       q[p[i]] = i;
     }
 
   bool neg = false;
 
   for (octave_idx_type i = 0; i < len; i++)
     {
-      octave_idx_type j = p[i], k = q[i];
+      octave_idx_type j = p[i];
+      octave_idx_type k = q[i];
       if (j != i)
         {
           p[k] = p[i];
           q[j] = q[i];
           neg = ! neg;
         }
     }
 
@@ -186,17 +187,18 @@ PermMatrix::eye (octave_idx_type n)
     p(i) = i;
 
   return PermMatrix (p, false, false);
 }
 
 PermMatrix
 operator *(const PermMatrix& a, const PermMatrix& b)
 {
-  const Array<octave_idx_type> ia = a.pvec (), ib = b.pvec ();
+  const Array<octave_idx_type> ia = a.pvec ();
+  const Array<octave_idx_type> ib = b.pvec ();
   PermMatrix r;
   octave_idx_type n = a.columns ();
   if (n != b.rows ())
     gripe_nonconformant ("operator *", n, n, b.rows (), b.rows ());
   else if (a._colp == b._colp)
     {
       r = PermMatrix ((a._colp
                        ? ia.index (idx_vector (ib))
diff --git a/liboctave/array/Sparse.cc b/liboctave/array/Sparse.cc
--- a/liboctave/array/Sparse.cc
+++ b/liboctave/array/Sparse.cc
@@ -139,17 +139,18 @@ Sparse<T>::SparseRep::celem (octave_idx_
 }
 
 template <class T>
 void
 Sparse<T>::SparseRep::maybe_compress (bool remove_zeros)
 {
   if (remove_zeros)
     {
-      octave_idx_type i = 0, k = 0;
+      octave_idx_type i = 0;
+      octave_idx_type k = 0;
       for (octave_idx_type j = 1; j <= ncols; j++)
         {
           octave_idx_type u = c[j];
           for (i = i; i < u; i++)
             if (d[i] != T ())
               {
                 d[k] = d[i];
                 r[k++] = r[i];
@@ -298,17 +299,19 @@ Sparse<T>::Sparse (const Array<T>& a, co
   if (nc < 0)
     nc = c.extent (0);
   else if (c.extent (nc) > nc)
     (*current_liboctave_error_handler)
       ("sparse: column index %d out of bound %d", r.extent (nc), nc);
 
   dimensions = dim_vector (nr, nc);
 
-  octave_idx_type n = a.numel (), rl = r.length (nr), cl = c.length (nc);
+  octave_idx_type n = a.numel ();
+  octave_idx_type rl = r.length (nr);
+  octave_idx_type cl = c.length (nc);
   bool a_scalar = n == 1;
   if (a_scalar)
     {
       if (rl != 1)
         n = rl;
       else if (cl != 1)
         n = cl;
     }
@@ -356,17 +359,18 @@ Sparse<T>::Sparse (const Array<T>& a, co
           change_capacity (nzm > new_nz ? nzm : new_nz);
           xcidx (0) = 0;
           xcidx (1) = new_nz;
           octave_idx_type *rri = ridx ();
           T *rrd = data ();
 
           octave_quit ();
 
-          octave_idx_type k = -1, l = -1;
+          octave_idx_type k = -1;
+          octave_idx_type l = -1;
 
           if (sum_terms)
             {
               // Sum repeated indices.
               for (octave_idx_type i = 0; i < n; i++)
                 {
                   if (rd[i] != l)
                     {
@@ -390,18 +394,20 @@ Sparse<T>::Sparse (const Array<T>& a, co
                       rrd[k] = a0;
                     }
                 }
             }
 
         }
       else
         {
-          idx_vector rr = r, cc = c;
-          const octave_idx_type *rd = rr.raw (), *cd = cc.raw ();
+          idx_vector rr = r;
+          idx_vector cc = c;
+          const octave_idx_type *rd = rr.raw ();
+          const octave_idx_type *cd = cc.raw ();
           OCTAVE_LOCAL_BUFFER_INIT (octave_idx_type, ci, nc+1, 0);
           ci[0] = 0;
           // Bin counts of column indices.
           for (octave_idx_type i = 0; i < n; i++)
             ci[cd[i]+1]++;
           // Make them cumulative, shifted one to right.
           for (octave_idx_type i = 1, s = 0; i <= nc; i++)
             {
@@ -420,17 +426,18 @@ Sparse<T>::Sparse (const Array<T>& a, co
             else
               sidx[ci[cd[i]+1]++] = rd[i];
 
           // Subsorts. We don't need a stable sort, all values are equal.
           xcidx (0) = 0;
           for (octave_idx_type j = 0; j < nc; j++)
             {
               std::sort (sidx + ci[j], sidx + ci[j+1]);
-              octave_idx_type l = -1, nzj = 0;
+              octave_idx_type l = -1;
+              octave_idx_type nzj = 0;
               // Count.
               for (octave_idx_type i = ci[j]; i < ci[j+1]; i++)
                 {
                   octave_idx_type k = sidx[i];
                   if (k != l)
                     {
                       l = k;
                       nzj++;
@@ -485,17 +492,18 @@ Sparse<T>::Sparse (const Array<T>& a, co
   else if (cl == 1)
     {
       // Sparse column vector. Sort row indices.
       Array<octave_idx_type> rsi;
       idx_vector rs = r.sorted (rsi);
 
       octave_quit ();
 
-      const octave_idx_type *rd = rs.raw (), *rdi = rsi.data ();
+      const octave_idx_type *rd = rs.raw ();
+      const octave_idx_type *rdi = rsi.data ();
       // Count unique indices.
       octave_idx_type new_nz = 1;
       for (octave_idx_type i = 1; i < n; i++)
         new_nz += rd[i-1] != rd[i];
       // Allocate result.
       change_capacity (nzm > new_nz ? nzm : new_nz);
       xcidx (0) = 0;
       xcidx (1) = new_nz;
@@ -532,18 +540,20 @@ Sparse<T>::Sparse (const Array<T>& a, co
               rrd[k] = a(rdi[i]);
             }
         }
 
       maybe_compress (true);
     }
   else
     {
-      idx_vector rr = r, cc = c;
-      const octave_idx_type *rd = rr.raw (), *cd = cc.raw ();
+      idx_vector rr = r;
+      idx_vector cc = c;
+      const octave_idx_type *rd = rr.raw ();
+      const octave_idx_type *cd = cc.raw ();
       OCTAVE_LOCAL_BUFFER_INIT (octave_idx_type, ci, nc+1, 0);
       ci[0] = 0;
       // Bin counts of column indices.
       for (octave_idx_type i = 0; i < n; i++)
         ci[cd[i]+1]++;
       // Make them cumulative, shifted one to right.
       for (octave_idx_type i = 1, s = 0; i <= nc; i++)
         {
@@ -567,17 +577,18 @@ Sparse<T>::Sparse (const Array<T>& a, co
           p.second = i;
         }
 
       // Subsorts. We don't need a stable sort, the second index stabilizes it.
       xcidx (0) = 0;
       for (octave_idx_type j = 0; j < nc; j++)
         {
           std::sort (spairs + ci[j], spairs + ci[j+1]);
-          octave_idx_type l = -1, nzj = 0;
+          octave_idx_type l = -1;
+          octave_idx_type nzj = 0;
           // Count.
           for (octave_idx_type i = ci[j]; i < ci[j+1]; i++)
             {
               octave_idx_type k = spairs[i].first;
               if (k != l)
                 {
                   l = k;
                   nzj++;
@@ -896,17 +907,18 @@ Sparse<T>::permute (const Array<octave_i
 
   return trans ? this->transpose () : *this;
 }
 
 template <class T>
 void
 Sparse<T>::resize1 (octave_idx_type n)
 {
-  octave_idx_type nr = rows (), nc = cols ();
+  octave_idx_type nr = rows ();
+  octave_idx_type nc = cols ();
 
   if (nr == 0)
     resize (1, std::max (nc, n));
   else if (nc == 0)
     resize (nr, (n + nr - 1) / nr); // Ain't it wicked?
   else if (nr == 1)
     resize (1, n);
   else if (nc == 1)
@@ -945,17 +957,18 @@ Sparse<T>::resize (octave_idx_type r, oc
     return;
 
   // This wouldn't be necessary for r >= rows () if nrows wasn't part of the
   // Sparse rep. It is not good for anything in there.
   make_unique ();
 
   if (r < rows ())
     {
-      octave_idx_type i = 0, k = 0;
+      octave_idx_type i = 0;
+      octave_idx_type k = 0;
       for (octave_idx_type j = 1; j <= rep->ncols; j++)
         {
           octave_idx_type u = xcidx (j);
           for (i = i; i < u; i++)
             if (xridx (i) < r)
               {
                 xdata (k) = xdata (i);
                 xridx (k++) = xridx (i);
@@ -1178,17 +1191,19 @@ Sparse<T>::delete_elements (const idx_ve
           xcidx (1) = nz_new;
         }
       else
         {
           OCTAVE_LOCAL_BUFFER (octave_idx_type, ridx_new, nz);
           OCTAVE_LOCAL_BUFFER (T, data_new, nz);
           idx_vector sidx = idx.sorted (true);
           const octave_idx_type *sj = sidx.raw ();
-          octave_idx_type sl = sidx.length (nel), nz_new = 0, j = 0;
+          octave_idx_type sl = sidx.length (nel);
+          octave_idx_type nz_new = 0;
+          octave_idx_type j = 0;
           for (octave_idx_type i = 0; i < nz; i++)
             {
               octave_idx_type r = tmp.ridx (i);
               for (; j < sl && sj[j] < r; j++) ;
               if (j == sl || sj[j] > r)
                 {
                   data_new[nz_new] = tmp.data (i);
                   ridx_new[nz_new++] = r - j;
@@ -1483,17 +1498,18 @@ Sparse<T>::index (const idx_vector& idx,
         {
           // If indexing a sparse column vector by a vector, the result is a
           // sparse column vector, otherwise it inherits the shape of index.
           // Vector transpose is cheap, so do it right here.
           const Array<octave_idx_type> idxa = (idx_dims(0) == 1
                                                ? idx.as_array ().transpose ()
                                                : idx.as_array ());
 
-          octave_idx_type new_nr = idxa.rows (), new_nc = idxa.cols ();
+          octave_idx_type new_nr = idxa.rows ();
+          octave_idx_type new_nc = idxa.cols ();
 
           // Lookup.
           // FIXME: Could specialize for sorted idx?
           NoAlias< Array<octave_idx_type> > lidx (dim_vector (new_nr, new_nc));
           for (octave_idx_type i = 0; i < new_nr*new_nc; i++)
             lidx(i) = lblookup (ridx (), nz, idxa(i));
 
           // Count matches.
@@ -1531,17 +1547,19 @@ Sparse<T>::index (const idx_vector& idx,
   else if (nr == 1)
     {
       octave_idx_type lb, ub;
       if (idx.is_scalar ())
         retval = Sparse<T> (1, 1, elem (0, idx(0)));
       else if (idx.is_cont_range (nel, lb, ub))
         {
           // Special-case a contiguous range.
-          octave_idx_type lbi = cidx (lb), ubi = cidx (ub), new_nz = ubi - lbi;
+          octave_idx_type lbi = cidx (lb);
+          octave_idx_type ubi = cidx (ub);
+          octave_idx_type new_nz = ubi - lbi;
           retval = Sparse<T> (1, ub - lb, new_nz);
           copy_or_memcpy (new_nz, data () + lbi, retval.data ());
           fill_or_memset (new_nz, static_cast<octave_idx_type> (0),
                           retval.ridx ());
           mx_inline_sub (ub - lb + 1, retval.cidx (), cidx () + lb, lbi);
         }
       else
         {
@@ -1616,17 +1634,19 @@ Sparse<T>::index (const idx_vector& idx_
     {
       // Great, we're just manipulating columns. This is going to be quite
       // efficient, because the columns can stay compressed as they are.
       if (idx_j.is_colon ())
         retval = *this; // Shallow copy.
       else if (idx_j.is_cont_range (nc, lb, ub))
         {
           // Special-case a contiguous range.
-          octave_idx_type lbi = cidx (lb), ubi = cidx (ub), new_nz = ubi - lbi;
+          octave_idx_type lbi = cidx (lb);
+          octave_idx_type ubi = cidx (ub);
+          octave_idx_type new_nz = ubi - lbi;
           retval = Sparse<T> (nr, ub - lb, new_nz);
           copy_or_memcpy (new_nz, data () + lbi, retval.data ());
           copy_or_memcpy (new_nz, ridx () + lbi, retval.ridx ());
           mx_inline_sub (ub - lb + 1, retval.cidx (), cidx () + lb, lbi);
         }
       else
         {
           // Count new nonzero elements.
@@ -1747,17 +1767,18 @@ Sparse<T>::index (const idx_vector& idx_
         {
           // It's nr:-1:1. Just flip all columns.
           for (octave_idx_type j = 0; j < m; j++)
             {
               octave_quit ();
               octave_idx_type jj = idx_j(j);
               octave_idx_type lj = cidx (jj);
               octave_idx_type nzj = cidx (jj+1) - cidx (jj);
-              octave_idx_type li = retval.xcidx (j), uj = lj + nzj - 1;
+              octave_idx_type li = retval.xcidx (j);
+              octave_idx_type uj = lj + nzj - 1;
               for (octave_idx_type i = 0; i < nzj; i++)
                 {
                   retval.xdata (li + i) = data (uj - i); // Copy in reverse order.
                   retval.xridx (li + i) = nr - 1 - ridx (uj - i); // Ditto with transform.
                 }
             }
         }
       else
@@ -1854,17 +1875,18 @@ Sparse<T>::assign (const idx_vector& idx
 
           octave_idx_type lb, ub;
           if (idx.is_cont_range (nr, lb, ub))
             {
               // Special-case a contiguous range.
               // Look-up indices first.
               octave_idx_type li = lblookup (ridx (), nz, lb);
               octave_idx_type ui = lblookup (ridx (), nz, ub);
-              octave_idx_type rnz = rhs.nnz (), new_nz = nz - (ui - li) + rnz;
+              octave_idx_type rnz = rhs.nnz ();
+              octave_idx_type new_nz = nz - (ui - li) + rnz;
 
               if (new_nz >= nz && new_nz <= capacity ())
                 {
                   // Adding/overwriting elements, enough capacity allocated.
 
                   if (new_nz > nz)
                     {
                       // Make room first.
@@ -2034,18 +2056,20 @@ Sparse<T>::assign (const idx_vector& idx
           octave_idx_type lb, ub;
           // Great, we're just manipulating columns. This is going to be quite
           // efficient, because the columns can stay compressed as they are.
           if (idx_j.is_colon ())
             *this = rhs; // Shallow copy.
           else if (idx_j.is_cont_range (nc, lb, ub))
             {
               // Special-case a contiguous range.
-              octave_idx_type li = cidx (lb), ui = cidx (ub);
-              octave_idx_type rnz = rhs.nnz (), new_nz = nz - (ui - li) + rnz;
+              octave_idx_type li = cidx (lb);
+              octave_idx_type ui = cidx (ub);
+              octave_idx_type rnz = rhs.nnz ();
+              octave_idx_type new_nz = nz - (ui - li) + rnz;
 
               if (new_nz >= nz && new_nz <= capacity ())
                 {
                   // Adding/overwriting elements, enough capacity allocated.
 
                   if (new_nz > nz)
                     {
                       // Make room first.
@@ -2124,17 +2148,19 @@ Sparse<T>::assign (const idx_vector& idx
               for (octave_idx_type i = 0; i < nc; i++)
                 xcidx (i+1) += xcidx (i);
 
               change_capacity (nnz ());
 
               // Merge columns.
               for (octave_idx_type i = 0; i < nc; i++)
                 {
-                  octave_idx_type l = xcidx (i), u = xcidx (i+1), j = jsav[i];
+                  octave_idx_type l = xcidx (i);
+                  octave_idx_type u = xcidx (i+1);
+                  octave_idx_type j = jsav[i];
                   if (j >= 0)
                     {
                       // from rhs
                       octave_idx_type k = rhs.cidx (j);
                       copy_or_memcpy (u - l, rhs.data () + k, xdata () + l);
                       copy_or_memcpy (u - l, rhs.ridx () + k, xridx () + l);
                     }
                   else
@@ -2600,17 +2626,18 @@ Sparse<T>::cat (int dim, octave_idx_type
             octave_idx_type rcum = 0;
             for (octave_idx_type i = 0; i < n; i++)
               {
                 const Sparse<T>& spi = sparse_list[i];
                 // Skipping empty matrices. See the comment in Array.cc.
                 if (spi.is_empty ())
                   continue;
 
-                octave_idx_type kl = spi.cidx (j), ku = spi.cidx (j+1);
+                octave_idx_type kl = spi.cidx (j);
+                octave_idx_type ku = spi.cidx (j+1);
                 for (octave_idx_type k = kl; k < ku; k++, l++)
                   {
                     retval.xridx (l) = spi.ridx (k) + rcum;
                     retval.xdata (l) = spi.data (k);
                   }
 
                 rcum += spi.rows ();
               }
diff --git a/liboctave/array/Sparse.h b/liboctave/array/Sparse.h
--- a/liboctave/array/Sparse.h
+++ b/liboctave/array/Sparse.h
@@ -295,23 +295,25 @@ public:
 
   T range_error (const char *fcn, const Array<octave_idx_type>& ra_idx) const;
   T& range_error (const char *fcn, const Array<octave_idx_type>& ra_idx);
 
   // No checking, even for multiple references, ever.
 
   T& xelem (octave_idx_type n)
   {
-    octave_idx_type i = n % rows (), j = n / rows ();
+    octave_idx_type i = n % rows ();
+    octave_idx_type j = n / rows ();
     return xelem (i, j);
   }
 
   T xelem (octave_idx_type n) const
   {
-    octave_idx_type i = n % rows (), j = n / rows ();
+    octave_idx_type i = n % rows ();
+    octave_idx_type j = n / rows ();
     return xelem (i, j);
   }
 
   T& xelem (octave_idx_type i, octave_idx_type j) { return rep->elem (i, j); }
   T xelem (octave_idx_type i, octave_idx_type j) const
   {
     return rep->celem (i, j);
   }
diff --git a/liboctave/array/boolSparse.cc b/liboctave/array/boolSparse.cc
--- a/liboctave/array/boolSparse.cc
+++ b/liboctave/array/boolSparse.cc
@@ -138,17 +138,19 @@ SparseBoolMatrix::all (int dim) const
 {
   SPARSE_ALL_OP (dim);
 }
 
 SparseBoolMatrix
 SparseBoolMatrix::any (int dim) const
 {
   Sparse<bool> retval;
-  octave_idx_type nr = rows (), nc = cols (), nz = nnz ();
+  octave_idx_type nr = rows ();
+  octave_idx_type nc = cols ();
+  octave_idx_type nz = nnz ();
   if (dim == -1)
     dim = (nr == 1 && nc != 1) ? 1 : 0;
 
   if (dim == 0)
     {
       // Result is a row vector.
       retval = Sparse<bool> (1, nc);
       retval.xcidx (0) = 0;
@@ -183,17 +185,19 @@ SparseBoolMatrix::any (int dim) const
 
   return retval;
 }
 
 SparseMatrix
 SparseBoolMatrix::sum (int dim) const
 {
   Sparse<double> retval;
-  octave_idx_type nr = rows (), nc = cols (), nz = nnz ();
+  octave_idx_type nr = rows ();
+  octave_idx_type nc = cols ();
+  octave_idx_type nz = nnz ();
   if (dim == -1)
     dim = (nr == 1 && nc != 1) ? 1 : 0;
 
   if (dim == 0)
     {
       // Result is a row vector.
       retval = Sparse<double> (1, nc);
       for (octave_idx_type i = 0; i < nc; i++)
diff --git a/liboctave/array/dDiagMatrix.cc b/liboctave/array/dDiagMatrix.cc
--- a/liboctave/array/dDiagMatrix.cc
+++ b/liboctave/array/dDiagMatrix.cc
@@ -324,17 +324,18 @@ operator * (const DiagMatrix& a, const D
   octave_idx_type b_nr = b.rows ();
   octave_idx_type b_nc = b.cols ();
 
   if (a_nc != b_nr)
     gripe_nonconformant ("operator *", a_nr, a_nc, b_nr, b_nc);
 
   DiagMatrix c (a_nr, b_nc);
 
-  octave_idx_type len = c.length (), lenm = len < a_nc ? len : a_nc;
+  octave_idx_type len = c.length ();
+  octave_idx_type lenm = len < a_nc ? len : a_nc;
 
   for (octave_idx_type i = 0; i < lenm; i++)
     c.dgxelem (i) = a.dgelem (i) * b.dgelem (i);
   for (octave_idx_type i = lenm; i < len; i++)
     c.dgxelem (i) = 0.0;
 
   return c;
 }
@@ -359,17 +360,18 @@ DiagMatrix::determinant (void) const
 
   return det;
 }
 
 double
 DiagMatrix::rcond (void) const
 {
   ColumnVector av = extract_diag (0).map<double> (fabs);
-  double amx = av.max (), amn = av.min ();
+  double amx = av.max ();
+  double amn = av.min ();
   return amx == 0 ? 0.0 : amn / amx;
 }
 
 std::ostream&
 operator << (std::ostream& os, const DiagMatrix& a)
 {
 //  int field_width = os.precision () + 7;
 
diff --git a/liboctave/array/dMatrix.cc b/liboctave/array/dMatrix.cc
--- a/liboctave/array/dMatrix.cc
+++ b/liboctave/array/dMatrix.cc
@@ -2007,32 +2007,36 @@ Matrix::solve (MatrixType &typ, const Co
                double& rcon) const
 {
   return solve (typ, b, info, rcon, 0);
 }
 
 static Matrix
 stack_complex_matrix (const ComplexMatrix& cm)
 {
-  octave_idx_type m = cm.rows (), n = cm.cols (), nel = m*n;
+  octave_idx_type m = cm.rows ();
+  octave_idx_type n = cm.cols ();
+  octave_idx_type nel = m*n;
   Matrix retval (m, 2*n);
   const Complex *cmd = cm.data ();
   double *rd = retval.fortran_vec ();
   for (octave_idx_type i = 0; i < nel; i++)
     {
       rd[i] = std::real (cmd[i]);
       rd[nel+i] = std::imag (cmd[i]);
     }
   return retval;
 }
 
 static ComplexMatrix
 unstack_complex_matrix (const Matrix& sm)
 {
-  octave_idx_type m = sm.rows (), n = sm.cols () / 2, nel = m*n;
+  octave_idx_type m = sm.rows ();
+  octave_idx_type n = sm.cols () / 2;
+  octave_idx_type nel = m*n;
   ComplexMatrix retval (m, n);
   const double *smd = sm.data ();
   Complex *rd = retval.fortran_vec ();
   for (octave_idx_type i = 0; i < nel; i++)
     rd[i] = Complex (smd[i], smd[nel+i]);
   return retval;
 }
 
@@ -3181,17 +3185,18 @@ get_blas_trans_arg (bool trans)
 // the general GEMM operation
 
 Matrix
 xgemm (const Matrix& a, const Matrix& b,
        blas_trans_type transa, blas_trans_type transb)
 {
   Matrix retval;
 
-  bool tra = transa != blas_no_trans, trb = transb != blas_no_trans;
+  bool tra = transa != blas_no_trans;
+  bool trb = transb != blas_no_trans;
 
   octave_idx_type a_nr = tra ? a.cols () : a.rows ();
   octave_idx_type a_nc = tra ? a.rows () : a.cols ();
 
   octave_idx_type b_nr = trb ? b.cols () : b.rows ();
   octave_idx_type b_nc = trb ? b.rows () : b.cols ();
 
   if (a_nc != b_nr)
@@ -3216,18 +3221,20 @@ xgemm (const Matrix& a, const Matrix& b,
                                    F77_CHAR_ARG_LEN (1)));
           for (int j = 0; j < a_nr; j++)
             for (int i = 0; i < j; i++)
               retval.xelem (j,i) = retval.xelem (i,j);
 
         }
       else
         {
-          octave_idx_type lda = a.rows (), tda = a.cols ();
-          octave_idx_type ldb = b.rows (), tdb = b.cols ();
+          octave_idx_type lda = a.rows ();
+          octave_idx_type tda = a.cols ();
+          octave_idx_type ldb = b.rows ();
+          octave_idx_type tdb = b.cols ();
 
           retval = Matrix (a_nr, b_nc);
           double *c = retval.fortran_vec ();
 
           if (b_nc == 1)
             {
               if (a_nr == 1)
                 F77_FUNC (xddot, XDDOT) (a_nc, a.data (), 1, b.data (), 1, *c);
diff --git a/liboctave/array/dSparse.cc b/liboctave/array/dSparse.cc
--- a/liboctave/array/dSparse.cc
+++ b/liboctave/array/dSparse.cc
@@ -160,17 +160,18 @@ SparseMatrix::SparseMatrix (const Sparse
       data (i) = a.data (i);
       ridx (i) = a.ridx (i);
     }
 }
 
 SparseMatrix::SparseMatrix (const DiagMatrix& a)
   : MSparse<double> (a.rows (), a.cols (), a.length ())
 {
-  octave_idx_type j = 0, l = a.length ();
+  octave_idx_type j = 0;
+  octave_idx_type l = a.length ();
   for (octave_idx_type i = 0; i < l; i++)
     {
       cidx (i) = j;
       if (a(i, i) != 0.0)
         {
           data (j) = a(i, i);
           ridx (j) = i;
           j++;
@@ -872,17 +873,18 @@ SparseMatrix::dinverse (MatrixType &matt
           else
             retval = *this;
 
           // Force make_unique to be called
           double *v = retval.data ();
 
           if (calccond)
             {
-              double dmax = 0., dmin = octave_Inf;
+              double dmax = 0.;
+              double dmin = octave_Inf;
               for (octave_idx_type i = 0; i < nr; i++)
                 {
                   double tmp = fabs (v[i]);
                   if (tmp > dmax)
                     dmax = tmp;
                   if (tmp < dmin)
                     dmin = tmp;
                 }
@@ -1407,17 +1409,18 @@ SparseMatrix::dsolve (MatrixType &mattyp
           else
             for (octave_idx_type j = 0; j < b.cols (); j++)
               for (octave_idx_type k = 0; k < nc; k++)
                 for (octave_idx_type i = cidx (k); i < cidx (k+1); i++)
                   retval(k,j) = b(ridx (i),j) / data (i);
 
           if (calc_cond)
             {
-              double dmax = 0., dmin = octave_Inf;
+              double dmax = 0.;
+              double dmin = octave_Inf;
               for (octave_idx_type i = 0; i < nm; i++)
                 {
                   double tmp = fabs (data (i));
                   if (tmp > dmax)
                     dmax = tmp;
                   if (tmp < dmin)
                     dmin = tmp;
                 }
@@ -1497,17 +1500,18 @@ SparseMatrix::dsolve (MatrixType &mattyp
                           retval.xdata (ii++) = b.data (k) / data (i);
                         }
                     }
                 retval.xcidx (j+1) = ii;
               }
 
           if (calc_cond)
             {
-              double dmax = 0., dmin = octave_Inf;
+              double dmax = 0.;
+              double dmin = octave_Inf;
               for (octave_idx_type i = 0; i < nm; i++)
                 {
                   double tmp = fabs (data (i));
                   if (tmp > dmax)
                     dmax = tmp;
                   if (tmp < dmin)
                     dmin = tmp;
                 }
@@ -1557,17 +1561,18 @@ SparseMatrix::dsolve (MatrixType &mattyp
           else
             for (octave_idx_type j = 0; j < b.cols (); j++)
               for (octave_idx_type k = 0; k < nc; k++)
                 for (octave_idx_type i = cidx (k); i < cidx (k+1); i++)
                   retval(k,j) = b(ridx (i),j) / data (i);
 
           if (calc_cond)
             {
-              double dmax = 0., dmin = octave_Inf;
+              double dmax = 0.;
+              double dmin = octave_Inf;
               for (octave_idx_type i = 0; i < nm; i++)
                 {
                   double tmp = fabs (data (i));
                   if (tmp > dmax)
                     dmax = tmp;
                   if (tmp < dmin)
                     dmin = tmp;
                 }
@@ -1647,17 +1652,18 @@ SparseMatrix::dsolve (MatrixType &mattyp
                           retval.xdata (ii++) = b.data (k) / data (i);
                         }
                     }
                 retval.xcidx (j+1) = ii;
               }
 
           if (calc_cond)
             {
-              double dmax = 0., dmin = octave_Inf;
+              double dmax = 0.;
+              double dmin = octave_Inf;
               for (octave_idx_type i = 0; i < nm; i++)
                 {
                   double tmp = fabs (data (i));
                   if (tmp > dmax)
                     dmax = tmp;
                   if (tmp < dmin)
                     dmin = tmp;
                 }
diff --git a/liboctave/array/dim-vector.cc b/liboctave/array/dim-vector.cc
--- a/liboctave/array/dim-vector.cc
+++ b/liboctave/array/dim-vector.cc
@@ -171,17 +171,18 @@ dim_vector::squeeze (void) const
 // other sizes remain intact.
 //
 // 2. A is 0x0, in which case B is the result
 // 3. B is 0x0, in which case A is the result
 
 bool
 dim_vector::concat (const dim_vector& dvb, int dim)
 {
-  int orig_nd = ndims (), ndb = dvb.ndims ();
+  int orig_nd = ndims ();
+  int ndb = dvb.ndims ();
   int new_nd = dim < ndb ? ndb : dim + 1;
   if (new_nd > orig_nd)
     resize (new_nd, 1);
   else
     new_nd = orig_nd;
 
   make_unique ();
 
diff --git a/liboctave/array/fCDiagMatrix.cc b/liboctave/array/fCDiagMatrix.cc
--- a/liboctave/array/fCDiagMatrix.cc
+++ b/liboctave/array/fCDiagMatrix.cc
@@ -447,17 +447,18 @@ operator * (const FloatComplexDiagMatrix
   octave_idx_type b_nr = b.rows ();
   octave_idx_type b_nc = b.cols ();
 
   if (a_nc != b_nr)
     gripe_nonconformant ("operator *", a_nr, a_nc, b_nr, b_nc);
 
   FloatComplexDiagMatrix c (a_nr, b_nc);
 
-  octave_idx_type len = c.length (), lenm = len < a_nc ? len : a_nc;
+  octave_idx_type len = c.length ();
+  octave_idx_type lenm = len < a_nc ? len : a_nc;
 
   for (octave_idx_type i = 0; i < lenm; i++)
     c.dgxelem (i) = a.dgelem (i) * b.dgelem (i);
   for (octave_idx_type i = lenm; i < len; i++)
     c.dgxelem (i) = 0.0f;
 
   return c;
 }
@@ -548,17 +549,18 @@ FloatComplexDiagMatrix::determinant (voi
 
   return det;
 }
 
 float
 FloatComplexDiagMatrix::rcond (void) const
 {
   FloatColumnVector av = extract_diag (0).map<float> (std::abs);
-  float amx = av.max (), amn = av.min ();
+  float amx = av.max ();
+  float amn = av.min ();
   return amx == 0 ? 0.0f : amn / amx;
 }
 
 // i/o
 
 std::ostream&
 operator << (std::ostream& os, const FloatComplexDiagMatrix& a)
 {
diff --git a/liboctave/array/fCMatrix.cc b/liboctave/array/fCMatrix.cc
--- a/liboctave/array/fCMatrix.cc
+++ b/liboctave/array/fCMatrix.cc
@@ -3790,18 +3790,20 @@ get_blas_trans_arg (bool trans, bool con
 // the general GEMM operation
 
 FloatComplexMatrix
 xgemm (const FloatComplexMatrix& a, const FloatComplexMatrix& b,
        blas_trans_type transa, blas_trans_type transb)
 {
   FloatComplexMatrix retval;
 
-  bool tra = transa != blas_no_trans, trb = transb != blas_no_trans;
-  bool cja = transa == blas_conj_trans, cjb = transb == blas_conj_trans;
+  bool tra = transa != blas_no_trans;
+  bool trb = transb != blas_no_trans;
+  bool cja = transa == blas_conj_trans;
+  bool cjb = transb == blas_conj_trans;
 
   octave_idx_type a_nr = tra ? a.cols () : a.rows ();
   octave_idx_type a_nc = tra ? a.rows () : a.cols ();
 
   octave_idx_type b_nr = trb ? b.cols () : b.rows ();
   octave_idx_type b_nc = trb ? b.rows () : b.cols ();
 
   if (a_nc != b_nr)
@@ -3847,18 +3849,20 @@ xgemm (const FloatComplexMatrix& a, cons
                 for (octave_idx_type i = 0; i < j; i++)
                   retval.xelem (j,i) = retval.xelem (i,j);
 
             }
 
         }
       else
         {
-          octave_idx_type lda = a.rows (), tda = a.cols ();
-          octave_idx_type ldb = b.rows (), tdb = b.cols ();
+          octave_idx_type lda = a.rows ();
+          octave_idx_type tda = a.cols ();
+          octave_idx_type ldb = b.rows ();
+          octave_idx_type tdb = b.cols ();
 
           retval = FloatComplexMatrix (a_nr, b_nc, 0.0);
           FloatComplex *c = retval.fortran_vec ();
 
           if (b_nc == 1 && a_nr == 1)
             {
               if (cja == cjb)
                 {
diff --git a/liboctave/array/fDiagMatrix.cc b/liboctave/array/fDiagMatrix.cc
--- a/liboctave/array/fDiagMatrix.cc
+++ b/liboctave/array/fDiagMatrix.cc
@@ -324,17 +324,18 @@ operator * (const FloatDiagMatrix& a, co
   octave_idx_type b_nr = b.rows ();
   octave_idx_type b_nc = b.cols ();
 
   if (a_nc != b_nr)
     gripe_nonconformant ("operator *", a_nr, a_nc, b_nr, b_nc);
 
   FloatDiagMatrix c (a_nr, b_nc);
 
-  octave_idx_type len = c.length (), lenm = len < a_nc ? len : a_nc;
+  octave_idx_type len = c.length ();
+  octave_idx_type lenm = len < a_nc ? len : a_nc;
 
   for (octave_idx_type i = 0; i < lenm; i++)
     c.dgxelem (i) = a.dgelem (i) * b.dgelem (i);
   for (octave_idx_type i = lenm; i < len; i++)
     c.dgxelem (i) = 0.0f;
 
   return c;
 }
@@ -359,17 +360,18 @@ FloatDiagMatrix::determinant (void) cons
 
   return det;
 }
 
 float
 FloatDiagMatrix::rcond (void) const
 {
   FloatColumnVector av = extract_diag (0).map<float> (fabsf);
-  float amx = av.max (), amn = av.min ();
+  float amx = av.max ();
+  float amn = av.min ();
   return amx == 0 ? 0.0f : amn / amx;
 }
 
 std::ostream&
 operator << (std::ostream& os, const FloatDiagMatrix& a)
 {
 //  int field_width = os.precision () + 7;
 
diff --git a/liboctave/array/fMatrix.cc b/liboctave/array/fMatrix.cc
--- a/liboctave/array/fMatrix.cc
+++ b/liboctave/array/fMatrix.cc
@@ -2021,32 +2021,36 @@ FloatMatrix::solve (MatrixType &typ, con
                     float& rcon) const
 {
   return solve (typ, b, info, rcon, 0);
 }
 
 static FloatMatrix
 stack_complex_matrix (const FloatComplexMatrix& cm)
 {
-  octave_idx_type m = cm.rows (), n = cm.cols (), nel = m*n;
+  octave_idx_type m = cm.rows ();
+  octave_idx_type n = cm.cols ();
+  octave_idx_type nel = m*n;
   FloatMatrix retval (m, 2*n);
   const FloatComplex *cmd = cm.data ();
   float *rd = retval.fortran_vec ();
   for (octave_idx_type i = 0; i < nel; i++)
     {
       rd[i] = std::real (cmd[i]);
       rd[nel+i] = std::imag (cmd[i]);
     }
   return retval;
 }
 
 static FloatComplexMatrix
 unstack_complex_matrix (const FloatMatrix& sm)
 {
-  octave_idx_type m = sm.rows (), n = sm.cols () / 2, nel = m*n;
+  octave_idx_type m = sm.rows ();
+  octave_idx_type n = sm.cols () / 2;
+  octave_idx_type nel = m*n;
   FloatComplexMatrix retval (m, n);
   const float *smd = sm.data ();
   FloatComplex *rd = retval.fortran_vec ();
   for (octave_idx_type i = 0; i < nel; i++)
     rd[i] = FloatComplex (smd[i], smd[nel+i]);
   return retval;
 }
 
@@ -3198,17 +3202,18 @@ get_blas_trans_arg (bool trans)
 // the general GEMM operation
 
 FloatMatrix
 xgemm (const FloatMatrix& a, const FloatMatrix& b,
        blas_trans_type transa, blas_trans_type transb)
 {
   FloatMatrix retval;
 
-  bool tra = transa != blas_no_trans, trb = transb != blas_no_trans;
+  bool tra = transa != blas_no_trans;
+  bool trb = transb != blas_no_trans;
 
   octave_idx_type a_nr = tra ? a.cols () : a.rows ();
   octave_idx_type a_nc = tra ? a.rows () : a.cols ();
 
   octave_idx_type b_nr = trb ? b.cols () : b.rows ();
   octave_idx_type b_nc = trb ? b.rows () : b.cols ();
 
   if (a_nc != b_nr)
@@ -3233,18 +3238,20 @@ xgemm (const FloatMatrix& a, const Float
                                    F77_CHAR_ARG_LEN (1)));
           for (int j = 0; j < a_nr; j++)
             for (int i = 0; i < j; i++)
               retval.xelem (j,i) = retval.xelem (i,j);
 
         }
       else
         {
-          octave_idx_type lda = a.rows (), tda = a.cols ();
-          octave_idx_type ldb = b.rows (), tdb = b.cols ();
+          octave_idx_type lda = a.rows ();
+          octave_idx_type tda = a.cols ();
+          octave_idx_type ldb = b.rows ();
+          octave_idx_type tdb = b.cols ();
 
           retval = FloatMatrix (a_nr, b_nc);
           float *c = retval.fortran_vec ();
 
           if (b_nc == 1)
             {
               if (a_nr == 1)
                 F77_FUNC (xsdot, XSDOT) (a_nc, a.data (), 1, b.data (), 1, *c);
diff --git a/liboctave/array/idx-vector.cc b/liboctave/array/idx-vector.cc
--- a/liboctave/array/idx-vector.cc
+++ b/liboctave/array/idx-vector.cc
@@ -590,17 +590,18 @@ idx_vector::idx_vector_rep::sort_idx (Ar
         {
           octave_idx_type j = cnt[i];
           cnt[i] = k;
           k += j;
         }
 
       for (octave_idx_type i = 0; i < len; i++)
         {
-          octave_idx_type j = data[i], k = cnt[j]++;
+          octave_idx_type j = data[i];
+          octave_idx_type k = cnt[j]++;
           new_data[k] = j;
           idx_data[k] = i;
         }
     }
 
   return new_rep.release ();
 }
 
@@ -831,17 +832,18 @@ idx_vector::maybe_reduce (octave_idx_typ
             reduced = true;
           }
           break;
 
         case class_range:
           {
             // (i:k:end,:) reduces to a range if i <= k and k divides n.
             idx_range_rep * r = dynamic_cast<idx_range_rep *> (rep);
-            octave_idx_type s = r->get_start (), l = r->length (n);
+            octave_idx_type s = r->get_start ();
+            octave_idx_type l = r->length (n);
             octave_idx_type t = r->get_step ();
             if (l*t == n)
               {
                 *this = new idx_range_rep (s, l * nj, t, DIRECT);
                 reduced = true;
               }
           }
           break;
@@ -855,45 +857,49 @@ idx_vector::maybe_reduce (octave_idx_typ
       switch (rep->idx_class ())
         {
         case class_colon:
           {
             // (:,i:j) reduces to a range (the step must be 1)
             idx_range_rep * rj = dynamic_cast<idx_range_rep *> (j.rep);
             if (rj->get_step () == 1)
               {
-                octave_idx_type sj = rj->get_start (), lj = rj->length (nj);
+                octave_idx_type sj = rj->get_start ();
+                octave_idx_type lj = rj->length (nj);
                 *this = new idx_range_rep (sj * n, lj * n, 1, DIRECT);
                 reduced = true;
               }
           }
           break;
 
         case class_scalar:
           {
             // (k,i:d:j) reduces to a range.
             idx_scalar_rep * r = dynamic_cast<idx_scalar_rep *> (rep);
             idx_range_rep * rj = dynamic_cast<idx_range_rep *> (j.rep);
             octave_idx_type k = r->get_data ();
-            octave_idx_type sj = rj->get_start (), lj = rj->length (nj);
+            octave_idx_type sj = rj->get_start ();
+            octave_idx_type lj = rj->length (nj);
             octave_idx_type tj = rj->get_step ();
             *this = new idx_range_rep (n * sj + k, lj, n * tj, DIRECT);
             reduced = true;
           }
           break;
 
         case class_range:
           {
             // (i:k:end,p:q) reduces to a range if i <= k and k divides n.
             // (ones (1, m), ones (1, n)) reduces to (ones (1, m*n))
             idx_range_rep * r = dynamic_cast<idx_range_rep *> (rep);
-            octave_idx_type s = r->get_start (), l = r->length (n);
+            octave_idx_type s = r->get_start ();
+            octave_idx_type l = r->length (n);
             octave_idx_type t = r->get_step ();
             idx_range_rep * rj = dynamic_cast<idx_range_rep *> (j.rep);
-            octave_idx_type sj = rj->get_start (), lj = rj->length (nj);
+            octave_idx_type sj = rj->get_start ();
+            octave_idx_type lj = rj->length (nj);
             octave_idx_type tj = rj->get_step ();
             if ((l*t == n && tj == 1) || (t == 0 && tj == 0))
               {
                 *this = new idx_range_rep (s + n * sj, l * lj, t, DIRECT);
                 reduced = true;
               }
           }
           break;
@@ -917,17 +923,18 @@ idx_vector::maybe_reduce (octave_idx_typ
           }
           break;
 
         case class_range:
           {
             // (i:d:j,k) reduces to a range.
             idx_range_rep * r = dynamic_cast<idx_range_rep *> (rep);
             idx_scalar_rep * rj = dynamic_cast<idx_scalar_rep *> (j.rep);
-            octave_idx_type s = r->get_start (), l = r->length (nj);
+            octave_idx_type s = r->get_start ();
+            octave_idx_type l = r->length (nj);
             octave_idx_type t = r->get_step ();
             octave_idx_type k = rj->get_data ();
             *this = new idx_range_rep (n * k + s, l, t, DIRECT);
             reduced = true;
           }
           break;
 
         case class_colon:
@@ -984,17 +991,18 @@ idx_vector::is_cont_range (octave_idx_ty
         u = l + 1;
         res = true;
       }
       break;
 
     case class_mask:
       {
         idx_mask_rep * r = dynamic_cast<idx_mask_rep *> (rep);
-        octave_idx_type ext = r->extent (0), len = r->length (0);
+        octave_idx_type ext = r->extent (0);
+        octave_idx_type len = r->length (0);
         if (ext == len)
           {
             l = 0;
             u = len;
             res = true;
           }
       }
 
@@ -1057,17 +1065,18 @@ idx_vector::copy_data (octave_idx_type *
     {
     case class_colon:
       current_liboctave_error_handler ("colon not allowed");
       break;
 
     case class_range:
       {
         idx_range_rep * r = dynamic_cast<idx_range_rep *> (rep);
-        octave_idx_type start = r->get_start (), step = r->get_step ();
+        octave_idx_type start = r->get_start ();
+        octave_idx_type step = r->get_step ();
         octave_idx_type i, j;
         if (step == 1)
           for (i = start, j = start + len; i < j; i++) *data++ = i;
         else if (step == -1)
           for (i = start, j = start - len; i > j; i--) *data++ = i;
         else
           for (i = 0, j = start; i < len; i++, j += step) *data++ = j;
       }
@@ -1111,17 +1120,18 @@ idx_vector::complement (octave_idx_type 
   idx_vector retval;
   if (extent (n) > n)
     (*current_liboctave_error_handler)
       ("internal error: out of range complement index requested");
 
   if (idx_class () == class_mask)
     {
       idx_mask_rep * r = dynamic_cast<idx_mask_rep *> (rep);
-      octave_idx_type nz = r->length (0), ext = r->extent (0);
+      octave_idx_type nz = r->length (0);
+      octave_idx_type ext = r->extent (0);
       Array<bool> mask (dim_vector (n, 1));
       const bool *data = r->get_data ();
       bool *ndata = mask.fortran_vec ();
       for (octave_idx_type i = 0; i < ext; i++)
         ndata[i] = ! data[i];
       for (octave_idx_type i = ext; i < n; i++)
         ndata[i] = true;
       retval = new idx_mask_rep (mask, n - nz);
@@ -1202,17 +1212,18 @@ idx_vector::inverse_permutation (octave_
 
 idx_vector
 idx_vector::unmask (void) const
 {
   if (idx_class () == class_mask)
     {
       idx_mask_rep * r = dynamic_cast<idx_mask_rep *> (rep);
       const bool *data = r->get_data ();
-      octave_idx_type ext = r->extent (0), len = r->length (0);
+      octave_idx_type ext = r->extent (0);
+      octave_idx_type len = r->length (0);
       octave_idx_type *idata = new octave_idx_type [len];
 
       for (octave_idx_type i = 0, j = 0; i < ext; i++)
         if (data[i])
           idata[j++] = i;
 
       ext = len > 0 ? idata[len - 1] + 1 : 0;
 
diff --git a/liboctave/array/idx-vector.h b/liboctave/array/idx-vector.h
--- a/liboctave/array/idx-vector.h
+++ b/liboctave/array/idx-vector.h
@@ -632,17 +632,18 @@ public:
       {
       case class_colon:
         copy_or_memcpy (len, src, dest);
         break;
 
       case class_range:
         {
           idx_range_rep * r = dynamic_cast<idx_range_rep *> (rep);
-          octave_idx_type start = r->get_start (), step = r->get_step ();
+          octave_idx_type start = r->get_start ();
+          octave_idx_type step = r->get_step ();
           const T *ssrc = src + start;
           if (step == 1)
             copy_or_memcpy (len, ssrc, dest);
           else if (step == -1)
             std::reverse_copy (ssrc - len + 1, ssrc + 1, dest);
           else if (step == 0)
             std::fill_n (dest, len, *ssrc);
           else
@@ -705,17 +706,18 @@ public:
       {
       case class_colon:
         copy_or_memcpy (len, src, dest);
         break;
 
       case class_range:
         {
           idx_range_rep * r = dynamic_cast<idx_range_rep *> (rep);
-          octave_idx_type start = r->get_start (), step = r->get_step ();
+          octave_idx_type start = r->get_start ();
+          octave_idx_type step = r->get_step ();
           T *sdest = dest + start;
           if (step == 1)
             copy_or_memcpy (len, src, sdest);
           else if (step == -1)
             std::reverse_copy (src, src + len, sdest - len + 1);
           else
             {
               for (octave_idx_type i = 0, j = 0; i < len; i++, j += step)
@@ -776,17 +778,18 @@ public:
       {
       case class_colon:
         std::fill (dest, dest + len, val);
         break;
 
       case class_range:
         {
           idx_range_rep * r = dynamic_cast<idx_range_rep *> (rep);
-          octave_idx_type start = r->get_start (), step = r->get_step ();
+          octave_idx_type start = r->get_start ();
+          octave_idx_type step = r->get_step ();
           T *sdest = dest + start;
           if (step == 1)
             std::fill (sdest, sdest + len, val);
           else if (step == -1)
             std::fill (sdest - len + 1, sdest + 1, val);
           else
             {
               for (octave_idx_type i = 0, j = 0; i < len; i++, j += step)
@@ -845,17 +848,18 @@ public:
       {
       case class_colon:
         for (octave_idx_type i = 0; i < len; i++) body (i);
         break;
 
       case class_range:
         {
           idx_range_rep * r = dynamic_cast<idx_range_rep *> (rep);
-          octave_idx_type start = r->get_start (), step = r->get_step ();
+          octave_idx_type start = r->get_start ();
+          octave_idx_type step = r->get_step ();
           octave_idx_type i, j;
           if (step == 1)
             for (i = start, j = start + len; i < j; i++) body (i);
           else if (step == -1)
             for (i = start, j = start - len; i > j; i--) body (i);
           else
             for (i = 0, j = start; i < len; i++, j += step) body (j);
         }
@@ -916,17 +920,18 @@ public:
           for (i = 0; i < len && body (i); i++) ;
           ret = i;
         }
         break;
 
       case class_range:
         {
           idx_range_rep * r = dynamic_cast<idx_range_rep *> (rep);
-          octave_idx_type start = r->get_start (), step = r->get_step ();
+          octave_idx_type start = r->get_start ();
+          octave_idx_type step = r->get_step ();
           octave_idx_type i, j;
           if (step == 1)
             for (i = start, j = start + len; i < j && body (i); i++) ;
           else if (step == -1)
             for (i = start, j = start - len; i > j && body (i); i--) ;
           else
             for (i = 0, j = start; i < len && body (j); i++, j += step) ;
           ret = i;
@@ -949,17 +954,18 @@ public:
           ret = i;
         }
         break;
 
       case class_mask:
         {
           idx_mask_rep * r = dynamic_cast<idx_mask_rep *> (rep);
           const bool *data = r->get_data ();
-          octave_idx_type ext = r->extent (0), j = 0;
+          octave_idx_type ext = r->extent (0);
+          octave_idx_type j = 0;
           for (octave_idx_type i = 0; i < ext; i++)
             {
               if (data[i])
                 {
                   if (body (i))
                     break;
                   else
                     j++;
diff --git a/liboctave/numeric/CmplxLU.cc b/liboctave/numeric/CmplxLU.cc
--- a/liboctave/numeric/CmplxLU.cc
+++ b/liboctave/numeric/CmplxLU.cc
@@ -95,17 +95,18 @@ void ComplexLU::update (const ComplexCol
   ComplexMatrix& r = a_fact;
 
   octave_idx_type m = l.rows ();
   octave_idx_type n = r.columns ();
   octave_idx_type k = l.columns ();
 
   if (u.length () == m && v.length () == n)
     {
-      ComplexColumnVector utmp = u, vtmp = v;
+      ComplexColumnVector utmp = u;
+      ComplexColumnVector vtmp = v;
       F77_XFCN (zlu1up, ZLU1UP, (m, n, l.fortran_vec (), m, r.fortran_vec (), k,
                                  utmp.fortran_vec (), vtmp.fortran_vec ()));
     }
   else
     (*current_liboctave_error_handler) ("luupdate: dimensions mismatch");
 }
 
 void ComplexLU::update (const ComplexMatrix& u, const ComplexMatrix& v)
@@ -119,17 +120,18 @@ void ComplexLU::update (const ComplexMat
   octave_idx_type m = l.rows ();
   octave_idx_type n = r.columns ();
   octave_idx_type k = l.columns ();
 
   if (u.rows () == m && v.rows () == n && u.cols () == v.cols ())
     {
       for (volatile octave_idx_type i = 0; i < u.cols (); i++)
         {
-          ComplexColumnVector utmp = u.column (i), vtmp = v.column (i);
+          ComplexColumnVector utmp = u.column (i);
+          ComplexColumnVector vtmp = v.column (i);
           F77_XFCN (zlu1up, ZLU1UP, (m, n, l.fortran_vec (),
                                      m, r.fortran_vec (), k,
                                      utmp.fortran_vec (), vtmp.fortran_vec ()));
         }
     }
   else
     (*current_liboctave_error_handler) ("luupdate: dimensions mismatch");
 }
@@ -144,17 +146,18 @@ void ComplexLU::update_piv (const Comple
   ComplexMatrix& r = a_fact;
 
   octave_idx_type m = l.rows ();
   octave_idx_type n = r.columns ();
   octave_idx_type k = l.columns ();
 
   if (u.length () == m && v.length () == n)
     {
-      ComplexColumnVector utmp = u, vtmp = v;
+      ComplexColumnVector utmp = u;
+      ComplexColumnVector vtmp = v;
       OCTAVE_LOCAL_BUFFER (Complex, w, m);
       for (octave_idx_type i = 0; i < m; i++) ipvt(i) += 1; // increment
       F77_XFCN (zlup1up, ZLUP1UP, (m, n, l.fortran_vec (),
                                    m, r.fortran_vec (), k,
                                    ipvt.fortran_vec (),
                                    utmp.data (), vtmp.data (), w));
       for (octave_idx_type i = 0; i < m; i++) ipvt(i) -= 1; // decrement
     }
@@ -175,17 +178,18 @@ void ComplexLU::update_piv (const Comple
   octave_idx_type k = l.columns ();
 
   if (u.rows () == m && v.rows () == n && u.cols () == v.cols ())
     {
       OCTAVE_LOCAL_BUFFER (Complex, w, m);
       for (octave_idx_type i = 0; i < m; i++) ipvt(i) += 1; // increment
       for (volatile octave_idx_type i = 0; i < u.cols (); i++)
         {
-          ComplexColumnVector utmp = u.column (i), vtmp = v.column (i);
+          ComplexColumnVector utmp = u.column (i);
+          ComplexColumnVector vtmp = v.column (i);
           F77_XFCN (zlup1up, ZLUP1UP, (m, n, l.fortran_vec (),
                                        m, r.fortran_vec (), k,
                                        ipvt.fortran_vec (),
                                        utmp.data (), vtmp.data (), w));
         }
       for (octave_idx_type i = 0; i < m; i++) ipvt(i) -= 1; // decrement
     }
   else
diff --git a/liboctave/numeric/CmplxQR.cc b/liboctave/numeric/CmplxQR.cc
--- a/liboctave/numeric/CmplxQR.cc
+++ b/liboctave/numeric/CmplxQR.cc
@@ -132,17 +132,18 @@ ComplexQR::init (const ComplexMatrix& a,
     }
 
   form (n, afact, tau, qr_type);
 }
 
 void ComplexQR::form (octave_idx_type n, ComplexMatrix& afact,
                       Complex *tau, qr_type_t qr_type)
 {
-  octave_idx_type m = afact.rows (), min_mn = std::min (m, n);
+  octave_idx_type m = afact.rows ();
+  octave_idx_type min_mn = std::min (m, n);
   octave_idx_type info;
 
   if (qr_type == qr_type_raw)
     {
       for (octave_idx_type j = 0; j < min_mn; j++)
         {
           octave_idx_type limit = j < min_mn - 1 ? j : min_mn - 1;
           for (octave_idx_type i = limit + 1; i < m; i++)
@@ -208,17 +209,18 @@ void
 ComplexQR::update (const ComplexColumnVector& u, const ComplexColumnVector& v)
 {
   octave_idx_type m = q.rows ();
   octave_idx_type n = r.columns ();
   octave_idx_type k = q.columns ();
 
   if (u.length () == m && v.length () == n)
     {
-      ComplexColumnVector utmp = u, vtmp = v;
+      ComplexColumnVector utmp = u;
+      ComplexColumnVector vtmp = v;
       OCTAVE_LOCAL_BUFFER (Complex, w, k);
       OCTAVE_LOCAL_BUFFER (double, rw, k);
       F77_XFCN (zqr1up, ZQR1UP, (m, n, k, q.fortran_vec (),
                                  m, r.fortran_vec (), k,
                                  utmp.fortran_vec (), vtmp.fortran_vec (),
                                  w, rw));
     }
   else
@@ -233,17 +235,18 @@ ComplexQR::update (const ComplexMatrix& 
   octave_idx_type k = q.columns ();
 
   if (u.rows () == m && v.rows () == n && u.cols () == v.cols ())
     {
       OCTAVE_LOCAL_BUFFER (Complex, w, k);
       OCTAVE_LOCAL_BUFFER (double, rw, k);
       for (volatile octave_idx_type i = 0; i < u.cols (); i++)
         {
-          ComplexColumnVector utmp = u.column (i), vtmp = v.column (i);
+          ComplexColumnVector utmp = u.column (i);
+          ComplexColumnVector vtmp = v.column (i);
           F77_XFCN (zqr1up, ZQR1UP, (m, n, k, q.fortran_vec (),
                                      m, r.fortran_vec (), k,
                                      utmp.fortran_vec (), vtmp.fortran_vec (),
                                      w, rw));
         }
     }
   else
     (*current_liboctave_error_handler) ("qrupdate: dimensions mismatch");
diff --git a/liboctave/numeric/base-qr.cc b/liboctave/numeric/base-qr.cc
--- a/liboctave/numeric/base-qr.cc
+++ b/liboctave/numeric/base-qr.cc
@@ -25,18 +25,20 @@ along with Octave; see the file COPYING.
 #endif
 
 #include "base-qr.h"
 
 template <class qr_type>
 base_qr<qr_type>::base_qr (const qr_type& q_arg, const qr_type& r_arg)
   : q (q_arg), r (r_arg)
 {
-  octave_idx_type q_nr = q.rows (), q_nc = q.columns ();
-  octave_idx_type r_nr = r.rows (), r_nc = r.columns ();
+  octave_idx_type q_nr = q.rows ();
+  octave_idx_type q_nc = q.columns ();
+  octave_idx_type r_nr = r.rows ();
+  octave_idx_type r_nc = r.columns ();
 
   if (! (q_nc == r_nr && (q_nr == q_nc || (q_nr > q_nc && r_nr == r_nc))))
     {
       q = qr_type ();
       r = qr_type ();
 
       (*current_liboctave_error_handler) ("QR dimensions mismatch");
     }
diff --git a/liboctave/numeric/bsxfun-defs.cc b/liboctave/numeric/bsxfun-defs.cc
--- a/liboctave/numeric/bsxfun-defs.cc
+++ b/liboctave/numeric/bsxfun-defs.cc
@@ -36,24 +36,26 @@ along with Octave; see the file COPYING.
 template <class R, class X, class Y>
 Array<R>
 do_bsxfun_op (const Array<X>& x, const Array<Y>& y,
               void (*op_vv) (size_t, R *, const X *, const Y *),
               void (*op_sv) (size_t, R *, X, const Y *),
               void (*op_vs) (size_t, R *, const X *, Y))
 {
   int nd = std::max (x.ndims (), y.ndims ());
-  dim_vector dvx = x.dims ().redim (nd), dvy = y.dims ().redim (nd);
+  dim_vector dvx = x.dims ().redim (nd);
+  dim_vector dvy = y.dims ().redim (nd);
 
   // Construct the result dimensions.
   dim_vector dvr;
   dvr.resize (nd);
   for (int i = 0; i < nd; i++)
     {
-      octave_idx_type xk = dvx(i), yk = dvy(i);
+      octave_idx_type xk = dvx(i);
+      octave_idx_type yk = dvy(i);
       if (xk == 1)
         dvr(i) = yk;
       else if (yk == 1 || xk == yk)
         dvr(i) = xk;
       else
         {
           (*current_liboctave_error_handler)
             ("bsxfun: nonconformant dimensions: %s and %s",
@@ -79,28 +81,30 @@ do_bsxfun_op (const Array<X>& x, const A
 
   if (retval.is_empty ())
     ; // do nothing
   else if (start == nd)
     op_vv (retval.numel (), rvec, xvec, yvec);
   else
     {
       // Determine the type of the low-level loop.
-      bool xsing = false, ysing = false;
+      bool xsing = false;
+      bool ysing = false;
       if (ldr == 1)
         {
           xsing = dvx(start) == 1;
           ysing = dvy(start) == 1;
           if (xsing || ysing)
             {
               ldr *= dvx(start) * dvy(start);
               start++;
             }
         }
-      dim_vector cdvx = dvx.cumulative (), cdvy = dvy.cumulative ();
+      dim_vector cdvx = dvx.cumulative ();
+      dim_vector cdvy = dvy.cumulative ();
       // Nullify singleton dims to achieve a spread effect.
       for (int i = std::max (start, octave_idx_type (1)); i < nd; i++)
         {
           if (dvx(i) == 1)
             cdvx(i-1) = 0;
           if (dvy(i) == 1)
             cdvy(i-1) = 0;
         }
@@ -134,17 +138,18 @@ do_bsxfun_op (const Array<X>& x, const A
 }
 
 template <class R, class X>
 void
 do_inplace_bsxfun_op (Array<R>& r, const Array<X>& x,
                       void (*op_vv) (size_t, R *, const X *),
                       void (*op_vs) (size_t, R *, X))
 {
-  dim_vector dvr = r.dims (), dvx = x.dims ();
+  dim_vector dvr = r.dims ();
+  dim_vector dvx = x.dims ();
   octave_idx_type nd = r.ndims ();
   dvx.redim (nd);
 
   const X* xvec = x.fortran_vec ();
   R* rvec = r.fortran_vec ();
 
   // Fold the common leading dimensions.
   octave_idx_type start, ldr = 1;
diff --git a/liboctave/numeric/bsxfun.h b/liboctave/numeric/bsxfun.h
--- a/liboctave/numeric/bsxfun.h
+++ b/liboctave/numeric/bsxfun.h
@@ -33,17 +33,18 @@ along with Octave; see the file COPYING.
 
 inline
 bool
 is_valid_bsxfun (const std::string& name, const dim_vector& dx,
                  const dim_vector& dy)
 {
   for (int i = 0; i < std::min (dx.length (), dy.length ()); i++)
     {
-      octave_idx_type xk = dx(i), yk = dy(i);
+      octave_idx_type xk = dx(i);
+      octave_idx_type yk = dy(i);
       // Check the three conditions for valid bsxfun dims
       if (! ( (xk == yk) || (xk == 1 && yk > 1) || (xk > 1 && yk == 1)))
         return false;
     }
 
   (*current_liboctave_warning_with_id_handler)
     ("Octave:broadcast", "%s: automatic broadcasting operation applied",
      name.c_str ());
@@ -54,23 +55,25 @@ is_valid_bsxfun (const std::string& name
 // since we can't change the size of the assigned-to matrix, we cannot
 // apply singleton expansion to it, so the conditions to check are
 // different here.
 inline
 bool
 is_valid_inplace_bsxfun (const std::string& name, const dim_vector& dr,
                          const dim_vector& dx)
 {
-  octave_idx_type drl = dr.length (), dxl = dx.length ();
+  octave_idx_type drl = dr.length ();
+  octave_idx_type dxl = dx.length ();
   if (drl < dxl)
     return false;
 
   for (int i = 0; i < drl; i++)
     {
-      octave_idx_type rk = dr(i), xk = dx(i);
+      octave_idx_type rk = dr(i);
+      octave_idx_type xk = dx(i);
 
       // Only two valid canditions to check; can't stretch rk
       if (! ( (rk == xk) || (rk > 1 && xk == 1)))
         return false;
     }
 
   (*current_liboctave_warning_with_id_handler)
     ("Octave:broadcast", "%s: automatic broadcasting operation applied",
diff --git a/liboctave/numeric/dbleLU.cc b/liboctave/numeric/dbleLU.cc
--- a/liboctave/numeric/dbleLU.cc
+++ b/liboctave/numeric/dbleLU.cc
@@ -94,17 +94,18 @@ void LU::update (const ColumnVector& u, 
   Matrix& r = a_fact;
 
   octave_idx_type m = l.rows ();
   octave_idx_type n = r.columns ();
   octave_idx_type k = l.columns ();
 
   if (u.length () == m && v.length () == n)
     {
-      ColumnVector utmp = u, vtmp = v;
+      ColumnVector utmp = u;
+      ColumnVector vtmp = v;
       F77_XFCN (dlu1up, DLU1UP, (m, n, l.fortran_vec (), m, r.fortran_vec (), k,
                                  utmp.fortran_vec (), vtmp.fortran_vec ()));
     }
   else
     (*current_liboctave_error_handler) ("luupdate: dimensions mismatch");
 }
 
 void LU::update (const Matrix& u, const Matrix& v)
@@ -118,17 +119,18 @@ void LU::update (const Matrix& u, const 
   octave_idx_type m = l.rows ();
   octave_idx_type n = r.columns ();
   octave_idx_type k = l.columns ();
 
   if (u.rows () == m && v.rows () == n && u.cols () == v.cols ())
     {
       for (volatile octave_idx_type i = 0; i < u.cols (); i++)
         {
-          ColumnVector utmp = u.column (i), vtmp = v.column (i);
+          ColumnVector utmp = u.column (i);
+          ColumnVector vtmp = v.column (i);
           F77_XFCN (dlu1up, DLU1UP, (m, n, l.fortran_vec (),
                                      m, r.fortran_vec (), k,
                                      utmp.fortran_vec (), vtmp.fortran_vec ()));
         }
     }
   else
     (*current_liboctave_error_handler) ("luupdate: dimensions mismatch");
 }
@@ -142,17 +144,18 @@ void LU::update_piv (const ColumnVector&
   Matrix& r = a_fact;
 
   octave_idx_type m = l.rows ();
   octave_idx_type n = r.columns ();
   octave_idx_type k = l.columns ();
 
   if (u.length () == m && v.length () == n)
     {
-      ColumnVector utmp = u, vtmp = v;
+      ColumnVector utmp = u;
+      ColumnVector vtmp = v;
       OCTAVE_LOCAL_BUFFER (double, w, m);
       for (octave_idx_type i = 0; i < m; i++) ipvt(i) += 1; // increment
       F77_XFCN (dlup1up, DLUP1UP, (m, n, l.fortran_vec (),
                                    m, r.fortran_vec (), k,
                                    ipvt.fortran_vec (),
                                    utmp.data (), vtmp.data (), w));
       for (octave_idx_type i = 0; i < m; i++) ipvt(i) -= 1; // decrement
     }
@@ -173,17 +176,18 @@ void LU::update_piv (const Matrix& u, co
   octave_idx_type k = l.columns ();
 
   if (u.rows () == m && v.rows () == n && u.cols () == v.cols ())
     {
       OCTAVE_LOCAL_BUFFER (double, w, m);
       for (octave_idx_type i = 0; i < m; i++) ipvt(i) += 1; // increment
       for (volatile octave_idx_type i = 0; i < u.cols (); i++)
         {
-          ColumnVector utmp = u.column (i), vtmp = v.column (i);
+          ColumnVector utmp = u.column (i);
+          ColumnVector vtmp = v.column (i);
           F77_XFCN (dlup1up, DLUP1UP, (m, n, l.fortran_vec (),
                                        m, r.fortran_vec (), k,
                                        ipvt.fortran_vec (),
                                        utmp.data (), vtmp.data (), w));
         }
       for (octave_idx_type i = 0; i < m; i++) ipvt(i) -= 1; // decrement
     }
   else
diff --git a/liboctave/numeric/dbleQR.cc b/liboctave/numeric/dbleQR.cc
--- a/liboctave/numeric/dbleQR.cc
+++ b/liboctave/numeric/dbleQR.cc
@@ -133,17 +133,18 @@ QR::init (const Matrix& a, qr_type_t qr_
     }
 
   form (n, afact, tau, qr_type);
 }
 
 void QR::form (octave_idx_type n, Matrix& afact,
                double *tau, qr_type_t qr_type)
 {
-  octave_idx_type m = afact.rows (), min_mn = std::min (m, n);
+  octave_idx_type m = afact.rows ();
+  octave_idx_type min_mn = std::min (m, n);
   octave_idx_type info;
 
   if (qr_type == qr_type_raw)
     {
       for (octave_idx_type j = 0; j < min_mn; j++)
         {
           octave_idx_type limit = j < min_mn - 1 ? j : min_mn - 1;
           for (octave_idx_type i = limit + 1; i < m; i++)
@@ -209,17 +210,18 @@ void
 QR::update (const ColumnVector& u, const ColumnVector& v)
 {
   octave_idx_type m = q.rows ();
   octave_idx_type n = r.columns ();
   octave_idx_type k = q.columns ();
 
   if (u.length () == m && v.length () == n)
     {
-      ColumnVector utmp = u, vtmp = v;
+      ColumnVector utmp = u;
+      ColumnVector vtmp = v;
       OCTAVE_LOCAL_BUFFER (double, w, 2*k);
       F77_XFCN (dqr1up, DQR1UP, (m, n, k, q.fortran_vec (),
                                  m, r.fortran_vec (), k,
                                  utmp.fortran_vec (), vtmp.fortran_vec (), w));
     }
   else
     (*current_liboctave_error_handler) ("qrupdate: dimensions mismatch");
 }
@@ -231,17 +233,18 @@ QR::update (const Matrix& u, const Matri
   octave_idx_type n = r.columns ();
   octave_idx_type k = q.columns ();
 
   if (u.rows () == m && v.rows () == n && u.cols () == v.cols ())
     {
       OCTAVE_LOCAL_BUFFER (double, w, 2*k);
       for (volatile octave_idx_type i = 0; i < u.cols (); i++)
         {
-          ColumnVector utmp = u.column (i), vtmp = v.column (i);
+          ColumnVector utmp = u.column (i);
+          ColumnVector vtmp = v.column (i);
           F77_XFCN (dqr1up, DQR1UP, (m, n, k, q.fortran_vec (),
                                      m, r.fortran_vec (), k,
                                      utmp.fortran_vec (), vtmp.fortran_vec (),
                                      w));
         }
     }
   else
     (*current_liboctave_error_handler) ("qrupdate: dimensions mismatch");
diff --git a/liboctave/numeric/fCmplxLU.cc b/liboctave/numeric/fCmplxLU.cc
--- a/liboctave/numeric/fCmplxLU.cc
+++ b/liboctave/numeric/fCmplxLU.cc
@@ -95,17 +95,18 @@ void FloatComplexLU::update (const Float
   FloatComplexMatrix& r = a_fact;
 
   octave_idx_type m = l.rows ();
   octave_idx_type n = r.columns ();
   octave_idx_type k = l.columns ();
 
   if (u.length () == m && v.length () == n)
     {
-      FloatComplexColumnVector utmp = u, vtmp = v;
+      FloatComplexColumnVector utmp = u;
+      FloatComplexColumnVector vtmp = v;
       F77_XFCN (clu1up, CLU1UP, (m, n, l.fortran_vec (), m, r.fortran_vec (), k,
                                  utmp.fortran_vec (), vtmp.fortran_vec ()));
     }
   else
     (*current_liboctave_error_handler) ("luupdate: dimensions mismatch");
 }
 
 void FloatComplexLU::update (const FloatComplexMatrix& u,
@@ -120,17 +121,18 @@ void FloatComplexLU::update (const Float
   octave_idx_type m = l.rows ();
   octave_idx_type n = r.columns ();
   octave_idx_type k = l.columns ();
 
   if (u.rows () == m && v.rows () == n && u.cols () == v.cols ())
     {
       for (volatile octave_idx_type i = 0; i < u.cols (); i++)
         {
-          FloatComplexColumnVector utmp = u.column (i), vtmp = v.column (i);
+          FloatComplexColumnVector utmp = u.column (i);
+          FloatComplexColumnVector vtmp = v.column (i);
           F77_XFCN (clu1up, CLU1UP, (m, n, l.fortran_vec (),
                                      m, r.fortran_vec (), k,
                                      utmp.fortran_vec (), vtmp.fortran_vec ()));
         }
     }
   else
     (*current_liboctave_error_handler) ("luupdate: dimensions mismatch");
 }
@@ -145,17 +147,18 @@ void FloatComplexLU::update_piv (const F
   FloatComplexMatrix& r = a_fact;
 
   octave_idx_type m = l.rows ();
   octave_idx_type n = r.columns ();
   octave_idx_type k = l.columns ();
 
   if (u.length () == m && v.length () == n)
     {
-      FloatComplexColumnVector utmp = u, vtmp = v;
+      FloatComplexColumnVector utmp = u;
+      FloatComplexColumnVector vtmp = v;
       OCTAVE_LOCAL_BUFFER (FloatComplex, w, m);
       for (octave_idx_type i = 0; i < m; i++) ipvt(i) += 1; // increment
       F77_XFCN (clup1up, CLUP1UP, (m, n, l.fortran_vec (),
                                    m, r.fortran_vec (), k,
                                    ipvt.fortran_vec (),
                                    utmp.data (), vtmp.data (), w));
       for (octave_idx_type i = 0; i < m; i++) ipvt(i) -= 1; // decrement
     }
@@ -177,17 +180,18 @@ void FloatComplexLU::update_piv (const F
   octave_idx_type k = l.columns ();
 
   if (u.rows () == m && v.rows () == n && u.cols () == v.cols ())
     {
       OCTAVE_LOCAL_BUFFER (FloatComplex, w, m);
       for (octave_idx_type i = 0; i < m; i++) ipvt(i) += 1; // increment
       for (volatile octave_idx_type i = 0; i < u.cols (); i++)
         {
-          FloatComplexColumnVector utmp = u.column (i), vtmp = v.column (i);
+          FloatComplexColumnVector utmp = u.column (i);
+          FloatComplexColumnVector vtmp = v.column (i);
           F77_XFCN (clup1up, CLUP1UP, (m, n, l.fortran_vec (),
                                        m, r.fortran_vec (), k,
                                        ipvt.fortran_vec (),
                                        utmp.data (), vtmp.data (), w));
         }
       for (octave_idx_type i = 0; i < m; i++) ipvt(i) -= 1; // decrement
     }
   else
diff --git a/liboctave/numeric/fCmplxQR.cc b/liboctave/numeric/fCmplxQR.cc
--- a/liboctave/numeric/fCmplxQR.cc
+++ b/liboctave/numeric/fCmplxQR.cc
@@ -135,17 +135,18 @@ FloatComplexQR::init (const FloatComplex
     }
 
   form (n, afact, tau, qr_type);
 }
 
 void FloatComplexQR::form (octave_idx_type n, FloatComplexMatrix& afact,
                            FloatComplex *tau, qr_type_t qr_type)
 {
-  octave_idx_type m = afact.rows (), min_mn = std::min (m, n);
+  octave_idx_type m = afact.rows ();
+  octave_idx_type min_mn = std::min (m, n);
   octave_idx_type info;
 
   if (qr_type == qr_type_raw)
     {
       for (octave_idx_type j = 0; j < min_mn; j++)
         {
           octave_idx_type limit = j < min_mn - 1 ? j : min_mn - 1;
           for (octave_idx_type i = limit + 1; i < m; i++)
@@ -212,17 +213,18 @@ FloatComplexQR::update (const FloatCompl
                         const FloatComplexColumnVector& v)
 {
   octave_idx_type m = q.rows ();
   octave_idx_type n = r.columns ();
   octave_idx_type k = q.columns ();
 
   if (u.length () == m && v.length () == n)
     {
-      FloatComplexColumnVector utmp = u, vtmp = v;
+      FloatComplexColumnVector utmp = u;
+      FloatComplexColumnVector vtmp = v;
       OCTAVE_LOCAL_BUFFER (FloatComplex, w, k);
       OCTAVE_LOCAL_BUFFER (float, rw, k);
       F77_XFCN (cqr1up, CQR1UP, (m, n, k, q.fortran_vec (),
                                  m, r.fortran_vec (), k,
                                  utmp.fortran_vec (), vtmp.fortran_vec (),
                                  w, rw));
     }
   else
@@ -238,17 +240,18 @@ FloatComplexQR::update (const FloatCompl
   octave_idx_type k = q.columns ();
 
   if (u.rows () == m && v.rows () == n && u.cols () == v.cols ())
     {
       OCTAVE_LOCAL_BUFFER (FloatComplex, w, k);
       OCTAVE_LOCAL_BUFFER (float, rw, k);
       for (volatile octave_idx_type i = 0; i < u.cols (); i++)
         {
-          FloatComplexColumnVector utmp = u.column (i), vtmp = v.column (i);
+          FloatComplexColumnVector utmp = u.column (i);
+          FloatComplexColumnVector vtmp = v.column (i);
           F77_XFCN (cqr1up, CQR1UP, (m, n, k, q.fortran_vec (),
                                      m, r.fortran_vec (), k,
                                      utmp.fortran_vec (), vtmp.fortran_vec (),
                                      w, rw));
         }
     }
   else
     (*current_liboctave_error_handler) ("qrupdate: dimensions mismatch");
diff --git a/liboctave/numeric/floatLU.cc b/liboctave/numeric/floatLU.cc
--- a/liboctave/numeric/floatLU.cc
+++ b/liboctave/numeric/floatLU.cc
@@ -94,17 +94,18 @@ void FloatLU::update (const FloatColumnV
   FloatMatrix& r = a_fact;
 
   octave_idx_type m = l.rows ();
   octave_idx_type n = r.columns ();
   octave_idx_type k = l.columns ();
 
   if (u.length () == m && v.length () == n)
     {
-      FloatColumnVector utmp = u, vtmp = v;
+      FloatColumnVector utmp = u;
+      FloatColumnVector vtmp = v;
       F77_XFCN (slu1up, SLU1UP, (m, n, l.fortran_vec (),
                                  m, r.fortran_vec (), k,
                                  utmp.fortran_vec (), vtmp.fortran_vec ()));
     }
   else
     (*current_liboctave_error_handler) ("luupdate: dimensions mismatch");
 }
 
@@ -119,17 +120,18 @@ void FloatLU::update (const FloatMatrix&
   octave_idx_type m = l.rows ();
   octave_idx_type n = r.columns ();
   octave_idx_type k = l.columns ();
 
   if (u.rows () == m && v.rows () == n && u.cols () == v.cols ())
     {
       for (volatile octave_idx_type i = 0; i < u.cols (); i++)
         {
-          FloatColumnVector utmp = u.column (i), vtmp = v.column (i);
+          FloatColumnVector utmp = u.column (i);
+          FloatColumnVector vtmp = v.column (i);
           F77_XFCN (slu1up, SLU1UP, (m, n, l.fortran_vec (),
                                      m, r.fortran_vec (), k,
                                      utmp.fortran_vec (), vtmp.fortran_vec ()));
         }
     }
   else
     (*current_liboctave_error_handler) ("luupdate: dimensions mismatch");
 }
@@ -144,17 +146,18 @@ void FloatLU::update_piv (const FloatCol
   FloatMatrix& r = a_fact;
 
   octave_idx_type m = l.rows ();
   octave_idx_type n = r.columns ();
   octave_idx_type k = l.columns ();
 
   if (u.length () == m && v.length () == n)
     {
-      FloatColumnVector utmp = u, vtmp = v;
+      FloatColumnVector utmp = u;
+      FloatColumnVector vtmp = v;
       OCTAVE_LOCAL_BUFFER (float, w, m);
       for (octave_idx_type i = 0; i < m; i++) ipvt(i) += 1; // increment
       F77_XFCN (slup1up, SLUP1UP, (m, n, l.fortran_vec (),
                                    m, r.fortran_vec (), k,
                                    ipvt.fortran_vec (),
                                    utmp.data (), vtmp.data (), w));
       for (octave_idx_type i = 0; i < m; i++) ipvt(i) -= 1; // decrement
     }
@@ -175,17 +178,18 @@ void FloatLU::update_piv (const FloatMat
   octave_idx_type k = l.columns ();
 
   if (u.rows () == m && v.rows () == n && u.cols () == v.cols ())
     {
       OCTAVE_LOCAL_BUFFER (float, w, m);
       for (octave_idx_type i = 0; i < m; i++) ipvt(i) += 1; // increment
       for (volatile octave_idx_type i = 0; i < u.cols (); i++)
         {
-          FloatColumnVector utmp = u.column (i), vtmp = v.column (i);
+          FloatColumnVector utmp = u.column (i);
+          FloatColumnVector vtmp = v.column (i);
           F77_XFCN (slup1up, SLUP1UP, (m, n, l.fortran_vec (),
                                        m, r.fortran_vec (), k,
                                        ipvt.fortran_vec (),
                                        utmp.data (), vtmp.data (), w));
         }
       for (octave_idx_type i = 0; i < m; i++) ipvt(i) -= 1; // decrement
     }
   else
diff --git a/liboctave/numeric/floatQR.cc b/liboctave/numeric/floatQR.cc
--- a/liboctave/numeric/floatQR.cc
+++ b/liboctave/numeric/floatQR.cc
@@ -131,17 +131,18 @@ FloatQR::init (const FloatMatrix& a, qr_
     }
 
   form (n, afact, tau, qr_type);
 }
 
 void FloatQR::form (octave_idx_type n, FloatMatrix& afact,
                     float *tau, qr_type_t qr_type)
 {
-  octave_idx_type m = afact.rows (), min_mn = std::min (m, n);
+  octave_idx_type m = afact.rows ();
+  octave_idx_type min_mn = std::min (m, n);
   octave_idx_type info;
 
   if (qr_type == qr_type_raw)
     {
       for (octave_idx_type j = 0; j < min_mn; j++)
         {
           octave_idx_type limit = j < min_mn - 1 ? j : min_mn - 1;
           for (octave_idx_type i = limit + 1; i < m; i++)
@@ -207,17 +208,18 @@ void
 FloatQR::update (const FloatColumnVector& u, const FloatColumnVector& v)
 {
   octave_idx_type m = q.rows ();
   octave_idx_type n = r.columns ();
   octave_idx_type k = q.columns ();
 
   if (u.length () == m && v.length () == n)
     {
-      FloatColumnVector utmp = u, vtmp = v;
+      FloatColumnVector utmp = u;
+      FloatColumnVector vtmp = v;
       OCTAVE_LOCAL_BUFFER (float, w, 2*k);
       F77_XFCN (sqr1up, SQR1UP, (m, n, k, q.fortran_vec (),
                                  m, r.fortran_vec (), k,
                                  utmp.fortran_vec (), vtmp.fortran_vec (), w));
     }
   else
     (*current_liboctave_error_handler) ("qrupdate: dimensions mismatch");
 }
@@ -229,17 +231,18 @@ FloatQR::update (const FloatMatrix& u, c
   octave_idx_type n = r.columns ();
   octave_idx_type k = q.columns ();
 
   if (u.rows () == m && v.rows () == n && u.cols () == v.cols ())
     {
       OCTAVE_LOCAL_BUFFER (float, w, 2*k);
       for (volatile octave_idx_type i = 0; i < u.cols (); i++)
         {
-          FloatColumnVector utmp = u.column (i), vtmp = v.column (i);
+          FloatColumnVector utmp = u.column (i);
+          FloatColumnVector vtmp = v.column (i);
           F77_XFCN (sqr1up, SQR1UP, (m, n, k, q.fortran_vec (),
                                      m, r.fortran_vec (), k,
                                      utmp.fortran_vec (), vtmp.fortran_vec (),
                                      w));
         }
     }
   else
     (*current_liboctave_error_handler) ("qrupdate: dimensions mismatch");
diff --git a/liboctave/numeric/lo-specfun.cc b/liboctave/numeric/lo-specfun.cc
--- a/liboctave/numeric/lo-specfun.cc
+++ b/liboctave/numeric/lo-specfun.cc
@@ -2691,17 +2691,17 @@ gammainc (double x, const NDArray& a)
 
   NDArray retval;
   NDArray result (dv);
 
   bool err;
 
   for (octave_idx_type i = 0; i < nel; i++)
     {
-      result (i) = gammainc (x, a(i), err);
+      result(i) = gammainc (x, a(i), err);
 
       if (err)
         goto done;
     }
 
   retval = result;
 
 done:
@@ -2717,17 +2717,17 @@ gammainc (const NDArray& x, double a)
 
   NDArray retval;
   NDArray result (dv);
 
   bool err;
 
   for (octave_idx_type i = 0; i < nel; i++)
     {
-      result (i) = gammainc (x(i), a, err);
+      result(i) = gammainc (x(i), a, err);
 
       if (err)
         goto done;
     }
 
   retval = result;
 
 done:
@@ -2747,17 +2747,17 @@ gammainc (const NDArray& x, const NDArra
   if (dv == a.dims ())
     {
       result.resize (dv);
 
       bool err;
 
       for (octave_idx_type i = 0; i < nel; i++)
         {
-          result (i) = gammainc (x(i), a(i), err);
+          result(i) = gammainc (x(i), a(i), err);
 
           if (err)
             goto done;
         }
 
       retval = result;
     }
   else
@@ -2896,17 +2896,17 @@ gammainc (float x, const FloatNDArray& a
 
   FloatNDArray retval;
   FloatNDArray result (dv);
 
   bool err;
 
   for (octave_idx_type i = 0; i < nel; i++)
     {
-      result (i) = gammainc (x, a(i), err);
+      result(i) = gammainc (x, a(i), err);
 
       if (err)
         goto done;
     }
 
   retval = result;
 
 done:
@@ -2922,17 +2922,17 @@ gammainc (const FloatNDArray& x, float a
 
   FloatNDArray retval;
   FloatNDArray result (dv);
 
   bool err;
 
   for (octave_idx_type i = 0; i < nel; i++)
     {
-      result (i) = gammainc (x(i), a, err);
+      result(i) = gammainc (x(i), a, err);
 
       if (err)
         goto done;
     }
 
   retval = result;
 
 done:
@@ -2952,17 +2952,17 @@ gammainc (const FloatNDArray& x, const F
   if (dv == a.dims ())
     {
       result.resize (dv);
 
       bool err;
 
       for (octave_idx_type i = 0; i < nel; i++)
         {
-          result (i) = gammainc (x(i), a(i), err);
+          result(i) = gammainc (x(i), a(i), err);
 
           if (err)
             goto done;
         }
 
       retval = result;
     }
   else
diff --git a/liboctave/numeric/oct-convn.cc b/liboctave/numeric/oct-convn.cc
--- a/liboctave/numeric/oct-convn.cc
+++ b/liboctave/numeric/oct-convn.cc
@@ -111,17 +111,18 @@ template <class T, class R>
 static MArray<T>
 convolve (const MArray<T>& a, const MArray<R>& b,
           convn_type ct)
 {
   if (a.is_empty () || b.is_empty ())
     return MArray<T> ();
 
   int nd = std::max (a.ndims (), b.ndims ());
-  const dim_vector adims = a.dims ().redim (nd), bdims = b.dims ().redim (nd);
+  const dim_vector adims = a.dims ().redim (nd);
+  const dim_vector bdims = b.dims ().redim (nd);
   dim_vector cdims = dim_vector::alloc (nd);
 
   for (int i = 0; i < nd; i++)
     {
       if (ct == convn_valid)
         cdims(i) = std::max (adims(i) - bdims(i) + 1,
                              static_cast<octave_idx_type> (0));
       else
diff --git a/liboctave/numeric/oct-norm.cc b/liboctave/numeric/oct-norm.cc
--- a/liboctave/numeric/oct-norm.cc
+++ b/liboctave/numeric/oct-norm.cc
@@ -322,17 +322,19 @@ template <class ColVectorT, class R>
 static void
 higham_subp (const ColVectorT& y, const ColVectorT& col,
              octave_idx_type nsamp, R p, R& lambda, R& mu)
 {
   R nrm = 0;
   for (octave_idx_type i = 0; i < nsamp; i++)
     {
       octave_quit ();
-      R fi = i*M_PI/nsamp, lambda1 = cos (fi), mu1 = sin (fi);
+      R fi = i*M_PI/nsamp;
+      R lambda1 = cos (fi);
+      R mu1 = sin (fi);
       R lmnr = std::pow (std::pow (std::abs (lambda1), p) +
                          std::pow (std::abs (mu1), p), 1/p);
       lambda1 /= lmnr; mu1 /= lmnr;
       R nrm1 = vector_norm (lambda1 * y + mu1 * col, p);
       if (nrm1 > nrm)
         {
           lambda = lambda1;
           mu = mu1;
@@ -353,17 +355,19 @@ higham_subp (const ColVectorT& y, const 
   typedef std::complex<R> CR;
   R nrm = 0;
   lambda = 1.0;
   CR lamcu = lambda / std::abs (lambda);
   // Probe magnitudes
   for (octave_idx_type i = 0; i < nsamp; i++)
     {
       octave_quit ();
-      R fi = i*M_PI/nsamp, lambda1 = cos (fi), mu1 = sin (fi);
+      R fi = i*M_PI/nsamp;
+      R lambda1 = cos (fi);
+      R mu1 = sin (fi);
       R lmnr = std::pow (std::pow (std::abs (lambda1), p) +
                          std::pow (std::abs (mu1), p), 1/p);
       lambda1 /= lmnr; mu1 /= lmnr;
       R nrm1 = vector_norm (lambda1 * lamcu * y + mu1 * col, p);
       if (nrm1 > nrm)
         {
           lambda = lambda1 * lamcu;
           mu = mu1;
@@ -410,17 +414,18 @@ VectorT dual_p (const VectorT& x, R p, R
 template <class MatrixT, class VectorT, class R>
 R higham (const MatrixT& m, R p, R tol, int maxiter,
           VectorT& x)
 {
   x.resize (m.columns (), 1);
   // the OSE part
   VectorT y(m.rows (), 1, 0), z(m.rows (), 1);
   typedef typename VectorT::element_type RR;
-  RR lambda = 0, mu = 1;
+  RR lambda = 0;
+  RR mu = 1;
   for (octave_idx_type k = 0; k < m.columns (); k++)
     {
       octave_quit ();
       VectorT col (m.column (k));
       if (k > 0)
         higham_subp (y, col, 4*k, p, lambda, mu);
       for (octave_idx_type i = 0; i < k; i++)
         x(i) *= lambda;
diff --git a/liboctave/numeric/sparse-dmsolve.cc b/liboctave/numeric/sparse-dmsolve.cc
--- a/liboctave/numeric/sparse-dmsolve.cc
+++ b/liboctave/numeric/sparse-dmsolve.cc
@@ -38,17 +38,18 @@ along with Octave; see the file COPYING.
 template <class T>
 static MSparse<T>
 dmsolve_extract (const MSparse<T> &A, const octave_idx_type *Pinv,
                  const octave_idx_type *Q, octave_idx_type rst,
                  octave_idx_type rend, octave_idx_type cst,
                  octave_idx_type cend, octave_idx_type maxnz = -1,
                  bool lazy = false)
 {
-  octave_idx_type nr = rend - rst, nc = cend - cst;
+  octave_idx_type nr = rend - rst;
+  octave_idx_type nc = cend - cst;
   maxnz = (maxnz < 0 ? A.nnz () : maxnz);
   octave_idx_type nz;
 
   // Cast to uint64 to handle overflow in this multiplication
   if (octave_uint64 (nr)*octave_uint64 (nc) < octave_uint64 (maxnz))
     nz = nr*nc;
   else
     nz = maxnz;
diff --git a/liboctave/operators/mx-inlines.cc b/liboctave/operators/mx-inlines.cc
--- a/liboctave/operators/mx-inlines.cc
+++ b/liboctave/operators/mx-inlines.cc
@@ -360,17 +360,18 @@ do_mx_inplace_op (Array<R>& r,
 template <class R, class X, class Y>
 inline Array<R>
 do_mm_binary_op (const Array<X>& x, const Array<Y>& y,
                  void (*op) (size_t, R *, const X *, const Y *) throw (),
                  void (*op1) (size_t, R *, X, const Y *) throw (),
                  void (*op2) (size_t, R *, const X *, Y) throw (),
                  const char *opname)
 {
-  dim_vector dx = x.dims (), dy = y.dims ();
+  dim_vector dx = x.dims ();
+  dim_vector dy = y.dims ();
   if (dx == dy)
     {
       Array<R> r (dx);
       op (r.length (), r.fortran_vec (), x.data (), y.data ());
       return r;
     }
   else if (is_valid_bsxfun (opname, dx, dy))
     {
@@ -405,17 +406,18 @@ do_sm_binary_op (const X& x, const Array
 
 template <class R, class X>
 inline Array<R>&
 do_mm_inplace_op (Array<R>& r, const Array<X>& x,
                   void (*op) (size_t, R *, const X *) throw (),
                   void (*op1) (size_t, R *, X) throw (),
                   const char *opname)
 {
-  dim_vector dr = r.dims (), dx = x.dims ();
+  dim_vector dr = r.dims ();
+  dim_vector dx = x.dims ();
   if (dr == dx)
     {
       op (r.length (), r.fortran_vec (), x.data ());
     }
   else if (is_valid_inplace_bsxfun (opname, dr, dx))
     {
       do_inplace_bsxfun_op (r, x, op, op1);
     }
@@ -851,17 +853,18 @@ OP_MINMAX_FCNN (mx_inline_min)
 OP_MINMAX_FCNN (mx_inline_max)
 
 #define OP_CUMMINMAX_FCN(F, OP) \
 template <class T> \
 void F (const T *v, T *r, octave_idx_type n) \
 { \
   if (! n) return; \
   T tmp = v[0]; \
-  octave_idx_type i = 1, j = 0; \
+  octave_idx_type i = 1; \
+  octave_idx_type j = 0; \
   if (xisnan (tmp)) \
     { \
       for (; i < n && xisnan (v[i]); i++) ; \
       for (; j < i; j++) r[j] = tmp; \
       if (i < n) tmp = v[i]; \
     } \
   for (; i < n; i++) \
     if (v[i] OP tmp) \
@@ -871,17 +874,18 @@ void F (const T *v, T *r, octave_idx_typ
       } \
   for (; j < i; j++) r[j] = tmp; \
 } \
 template <class T> \
 void F (const T *v, T *r, octave_idx_type *ri, octave_idx_type n) \
 { \
   if (! n) return; \
   T tmp = v[0]; octave_idx_type tmpi = 0; \
-  octave_idx_type i = 1, j = 0; \
+  octave_idx_type i = 1; \
+  octave_idx_type j = 0; \
   if (xisnan (tmp)) \
     { \
       for (; i < n && xisnan (v[i]); i++) ; \
       for (; j < i; j++) { r[j] = tmp; ri[j] = tmpi; } \
       if (i < n) { tmp = v[i]; tmpi = i; } \
     } \
   for (; i < n; i++) \
     if (v[i] OP tmp) \
@@ -1325,26 +1329,29 @@ do_mx_diff_op (const Array<R>& src, int 
 // T. Ogita, S. M. Rump, S. Oishi:
 // Accurate Sum And Dot Product,
 // SIAM J. Sci. Computing, Vol. 26, 2005
 
 template <class T>
 inline void twosum_accum (T& s, T& e,
                           const T& x)
 {
-  T s1 = s + x, t = s1 - s, e1 = (s - (s1 - t)) + (x - t);
+  T s1 = s + x;
+  T t = s1 - s;
+  T e1 = (s - (s1 - t)) + (x - t);
   s = s1;
   e += e1;
 }
 
 template <class T>
 inline T
 mx_inline_xsum (const T *v, octave_idx_type n)
 {
-  T s = 0, e = 0;
+  T s = 0;
+  T e = 0;
   for (octave_idx_type i = 0; i < n; i++)
     twosum_accum (s, e, v[i]);
 
   return s + e;
 }
 
 template <class T>
 inline void
diff --git a/liboctave/operators/mx-op-defs.h b/liboctave/operators/mx-op-defs.h
--- a/liboctave/operators/mx-op-defs.h
+++ b/liboctave/operators/mx-op-defs.h
@@ -594,17 +594,18 @@ FCN (const T& a, const T& b) \
   NDS_MINMAX_FCN (max, >, T, S) \
   NDND_MINMAX_FCN (max, >, T, S)
 
 // permutation matrix by matrix ops and vice versa
 
 #define PMM_MULTIPLY_OP(PM, M) \
 M operator * (const PM& p, const M& x) \
 { \
-  octave_idx_type nr = x.rows (), nc = x.columns (); \
+  octave_idx_type nr = x.rows (); \
+  octave_idx_type nc = x.columns (); \
   M result; \
   if (p.columns () != nr) \
     gripe_nonconformant ("operator *", p.rows (), p.columns (), nr, nc); \
   else \
     { \
       if (p.is_col_perm ()) \
         { \
           result = M (nr, nc); \
@@ -615,17 +616,18 @@ M operator * (const PM& p, const M& x) \
     } \
   \
   return result; \
 }
 
 #define MPM_MULTIPLY_OP(M, PM) \
 M operator * (const M& x, const PM& p) \
 { \
-  octave_idx_type nr = x.rows (), nc = x.columns (); \
+  octave_idx_type nr = x.rows (); \
+  octave_idx_type nc = x.columns (); \
   M result; \
   if (p.rows () != nc) \
     gripe_nonconformant ("operator *", nr, nc, p.rows (), p.columns ()); \
   else \
     { \
       if (p.is_col_perm ()) \
         result = x.index (idx_vector::colon, p.pvec ()); \
       else \
diff --git a/liboctave/util/caseless-str.h b/liboctave/util/caseless-str.h
--- a/liboctave/util/caseless-str.h
+++ b/liboctave/util/caseless-str.h
@@ -49,17 +49,18 @@ public:
 
   bool operator < (const std::string& s) const
   {
     const_iterator p1 = begin ();
     const_iterator p2 = s.begin ();
 
     while (p1 != end () && p2 != s.end ())
       {
-        char lp1 = std::tolower (*p1), lp2 = std::tolower (*p2);
+        char lp1 = std::tolower (*p1);
+        char lp2 = std::tolower (*p2);
 
         if ( lp1 > lp2 )
           return false;
         if ( lp1 < lp2)
           return true;
 
         p1++;
         p2++;
diff --git a/liboctave/util/kpse.cc b/liboctave/util/kpse.cc
--- a/liboctave/util/kpse.cc
+++ b/liboctave/util/kpse.cc
@@ -1607,17 +1607,20 @@ expand_amble (const std::string& text)
 
 /* Start at INDEX, and skip characters in TEXT. Set INDEX to the
    index of the character matching SATISFY.  This understands about
    quoting.  Return the character that caused us to stop searching;
    this is either the same as SATISFY, or 0. */
 static int
 brace_gobbler (const std::string& text, int& indx, int satisfy)
 {
-  int c = 0, level = 0, quoted = 0, pass_next = 0;
+  int c = 0;
+  int level = 0;
+  int quoted = 0;
+  int pass_next = 0;
 
   size_t text_len = text.length ();
 
   size_t i = indx;
 
   for (; i < text_len; i++)
     {
       c = text[i];
diff --git a/liboctave/util/lo-utils.cc b/liboctave/util/lo-utils.cc
--- a/liboctave/util/lo-utils.cc
+++ b/liboctave/util/lo-utils.cc
@@ -317,17 +317,18 @@ octave_read_fp_value (std::istream& is)
 
   return val;
 }
 
 template <typename T>
 std::complex<T>
 octave_read_cx_fp_value (std::istream& is)
 {
-  T re = 0.0, im = 0.0;
+  T re = 0.0;
+  T im = 0.0;
 
   std::complex<T> cx = 0.0;
 
   char ch = ' ';
 
   while (isspace (ch))
     ch = is.get ();
 
diff --git a/liboctave/util/oct-binmap.h b/liboctave/util/oct-binmap.h
--- a/liboctave/util/oct-binmap.h
+++ b/liboctave/util/oct-binmap.h
@@ -162,17 +162,18 @@ binmap (const Array<T>& xa, const R& y, 
   return result;
 }
 
 // Array-Array (treats singletons as scalars)
 template <class U, class T, class R, class F>
 Array<U>
 binmap (const Array<T>& xa, const Array<R>& ya, F fcn, const char *name)
 {
-  dim_vector xad = xa.dims (), yad = ya.dims ();
+  dim_vector xad = xa.dims ();
+  dim_vector yad = ya.dims ();
   if (xa.numel () == 1)
     return binmap<U, T, R, F> (xa(0), ya, fcn);
   else if (ya.numel () == 1)
     return binmap<U, T, R, F> (xa, ya(0), fcn);
   else if (xad != yad)
     {
       if (is_valid_bsxfun (name, xad, yad))
         {
@@ -263,50 +264,57 @@ binmap (const Sparse<T>& xs, const Spars
 
   T xzero = T ();
   R yzero = R ();
 
   U fz = fcn (xzero, yzero);
   if (fz == U ())
     {
       // Sparsity-preserving function. Do it efficiently.
-      octave_idx_type nr = xs.rows (), nc = xs.cols ();
+      octave_idx_type nr = xs.rows ();
+      octave_idx_type nc = xs.cols ();
       Sparse<T> retval (nr, nc);
 
       octave_idx_type nz = 0;
       // Count nonzeros.
       for (octave_idx_type j = 0; j < nc; j++)
         {
           octave_quit ();
-          octave_idx_type ix = xs.cidx (j), iy = ys.cidx (j);
-          octave_idx_type ux = xs.cidx (j+1), uy = ys.cidx (j+1);
+          octave_idx_type ix = xs.cidx (j);
+          octave_idx_type iy = ys.cidx (j);
+          octave_idx_type ux = xs.cidx (j+1);
+          octave_idx_type uy = ys.cidx (j+1);
           while (ix != ux || iy != uy)
             {
-              octave_idx_type rx = xs.ridx (ix), ry = ys.ridx (ix);
+              octave_idx_type rx = xs.ridx (ix);
+              octave_idx_type ry = ys.ridx (ix);
               ix += rx <= ry;
               iy += ry <= rx;
               nz++;
             }
 
           retval.xcidx (j+1) = nz;
         }
 
       // Allocate space.
       retval.change_capacity (retval.xcidx (nc));
 
       // Fill.
       nz = 0;
       for (octave_idx_type j = 0; j < nc; j++)
         {
           octave_quit ();
-          octave_idx_type ix = xs.cidx (j), iy = ys.cidx (j);
-          octave_idx_type ux = xs.cidx (j+1), uy = ys.cidx (j+1);
+          octave_idx_type ix = xs.cidx (j);
+          octave_idx_type iy = ys.cidx (j);
+          octave_idx_type ux = xs.cidx (j+1);
+          octave_idx_type uy = ys.cidx (j+1);
           while (ix != ux || iy != uy)
             {
-              octave_idx_type rx = xs.ridx (ix), ry = ys.ridx (ix);
+              octave_idx_type rx = xs.ridx (ix);
+              octave_idx_type ry = ys.ridx (ix);
               if (rx == ry)
                 {
                   retval.xridx (nz) = rx;
                   retval.xdata (nz) = fcn (xs.data (ix), ys.data (iy));
                   ix++;
                   iy++;
                 }
               else if (rx < ry)
diff --git a/liboctave/util/oct-cmplx.h b/liboctave/util/oct-cmplx.h
--- a/liboctave/util/oct-cmplx.h
+++ b/liboctave/util/oct-cmplx.h
@@ -35,41 +35,45 @@ typedef std::complex<float> FloatComplex
 // by their real parts; OTOH, it uses the same definition for max/min and sort.
 // The abs/arg comparison is definitely more useful (the other one is emulated
 // rather trivially), so let's be consistent and use that all over.
 
 #define DEF_COMPLEXR_COMP(OP, OPS) \
 template <class T> \
 inline bool operator OP (const std::complex<T>& a, const std::complex<T>& b) \
 { \
-  FLOAT_TRUNCATE const T ax = std::abs (a), bx = std::abs (b); \
+  FLOAT_TRUNCATE const T ax = std::abs (a); \
+  FLOAT_TRUNCATE const T bx = std::abs (b); \
   if (ax == bx) \
     { \
-      FLOAT_TRUNCATE const T ay = std::arg (a), by = std::arg (b); \
+      FLOAT_TRUNCATE const T ay = std::arg (a); \
+      FLOAT_TRUNCATE const T by = std::arg (b); \
       return ay OP by; \
     } \
   else \
     return ax OPS bx; \
 } \
 template <class T> \
 inline bool operator OP (const std::complex<T>& a, T b) \
 { \
-  FLOAT_TRUNCATE const T ax = std::abs (a), bx = std::abs (b); \
+  FLOAT_TRUNCATE const T ax = std::abs (a); \
+  FLOAT_TRUNCATE const T bx = std::abs (b); \
   if (ax == bx) \
     { \
       FLOAT_TRUNCATE const T ay = std::arg (a); \
       return ay OP 0; \
     } \
   else \
     return ax OPS bx; \
 } \
 template <class T> \
 inline bool operator OP (T a, const std::complex<T>& b) \
 { \
-  FLOAT_TRUNCATE const T ax = std::abs (a), bx = std::abs (b); \
+  FLOAT_TRUNCATE const T ax = std::abs (a); \
+  FLOAT_TRUNCATE const T bx = std::abs (b); \
   if (ax == bx) \
     { \
       FLOAT_TRUNCATE const T by = std::arg (b); \
       return 0 OP by; \
     } \
   else \
     return ax OPS bx; \
 }
diff --git a/liboctave/util/oct-inttypes.cc b/liboctave/util/oct-inttypes.cc
--- a/liboctave/util/oct-inttypes.cc
+++ b/liboctave/util/oct-inttypes.cc
@@ -275,39 +275,44 @@ octave_int_cmp_op::emulate_mop (double x
 
 // Define handlers for int64 multiplication
 
 template <>
 uint64_t
 octave_int_arith_base<uint64_t, false>::mul_internal (uint64_t x, uint64_t y)
 {
   // Get upper words
-  uint64_t ux = x >> 32, uy = y >> 32;
+  uint64_t ux = x >> 32;
+  uint64_t uy = y >> 32;
   uint64_t res;
   if (ux)
     {
       if (uy)
         goto overflow;
       else
         {
-          uint64_t ly = static_cast<uint32_t> (y), uxly = ux*ly;
+          uint64_t ly = static_cast<uint32_t> (y);
+          uint64_t uxly = ux*ly;
           if (uxly >> 32)
             goto overflow;
           uxly <<= 32; // never overflows
-          uint64_t lx = static_cast<uint32_t> (x), lxly = lx*ly;
+          uint64_t lx = static_cast<uint32_t> (x);
+          uint64_t lxly = lx*ly;
           res = add (uxly, lxly);
         }
     }
   else if (uy)
     {
-      uint64_t lx = static_cast<uint32_t> (x), uylx = uy*lx;
+      uint64_t lx = static_cast<uint32_t> (x);
+      uint64_t uylx = uy*lx;
       if (uylx >> 32)
         goto overflow;
       uylx <<= 32; // never overflows
-      uint64_t ly = static_cast<uint32_t> (y), lylx = ly*lx;
+      uint64_t ly = static_cast<uint32_t> (y);
+      uint64_t lylx = ly*lx;
       res = add (uylx, lylx);
     }
   else
     {
       uint64_t lx = static_cast<uint32_t> (x);
       uint64_t ly = static_cast<uint32_t> (y);
       res = lx*ly;
     }
@@ -325,45 +330,51 @@ octave_int_arith_base<int64_t, true>::mu
   // The signed case is far worse. The problem is that
   // even if neither integer fits into signed 32-bit range, the result may
   // still be OK. Uh oh.
 
   // Essentially, what we do is compute sign, multiply absolute values
   // (as above) and impose the sign.
   // FIXME: can we do something faster if we HAVE_FAST_INT_OPS?
 
-  uint64_t usx = octave_int_abs (x), usy = octave_int_abs (y);
+  uint64_t usx = octave_int_abs (x);
+  uint64_t usy = octave_int_abs (y);
   bool positive = (x < 0) == (y < 0);
 
   // Get upper words
-  uint64_t ux = usx >> 32, uy = usy >> 32;
+  uint64_t ux = usx >> 32;
+  uint64_t uy = usy >> 32;
   uint64_t res;
   if (ux)
     {
       if (uy)
         goto overflow;
       else
         {
-          uint64_t ly = static_cast<uint32_t> (usy), uxly = ux*ly;
+          uint64_t ly = static_cast<uint32_t> (usy);
+          uint64_t uxly = ux*ly;
           if (uxly >> 32)
             goto overflow;
           uxly <<= 32; // never overflows
-          uint64_t lx = static_cast<uint32_t> (usx), lxly = lx*ly;
+          uint64_t lx = static_cast<uint32_t> (usx);
+          uint64_t lxly = lx*ly;
           res = uxly + lxly;
           if (res < uxly)
             goto overflow;
         }
     }
   else if (uy)
     {
-      uint64_t lx = static_cast<uint32_t> (usx), uylx = uy*lx;
+      uint64_t lx = static_cast<uint32_t> (usx);
+      uint64_t uylx = uy*lx;
       if (uylx >> 32)
         goto overflow;
       uylx <<= 32; // never overflows
-      uint64_t ly = static_cast<uint32_t> (usy), lylx = ly*lx;
+      uint64_t ly = static_cast<uint32_t> (usy);
+      uint64_t lylx = ly*lx;
       res = uylx + lylx;
       if (res < uylx)
         goto overflow;
     }
   else
     {
       uint64_t lx = static_cast<uint32_t> (usx);
       uint64_t ly = static_cast<uint32_t> (usy);
@@ -491,21 +502,24 @@ DOUBLE_INT_BINOP_DECL (-, int64)
 // not immediately obvious, this should work even w.r.t. rounding (none of the
 // summands lose precision).
 
 // Multiplies two unsigned 64-bit ints to get a 128-bit number represented
 // as four 32-bit words.
 static void
 umul128 (uint64_t x, uint64_t y, uint32_t w[4])
 {
-  uint64_t lx = static_cast<uint32_t> (x), ux = x >> 32;
-  uint64_t ly = static_cast<uint32_t> (y), uy = y >> 32;
+  uint64_t lx = static_cast<uint32_t> (x);
+  uint64_t ux = x >> 32;
+  uint64_t ly = static_cast<uint32_t> (y);
+  uint64_t uy = y >> 32;
   uint64_t a = lx * ly;
   w[0] = a; a >>= 32;
-  uint64_t uxly = ux*ly, uylx = uy*lx;
+  uint64_t uxly = ux*ly;
+  uint64_t uylx = uy*lx;
   a += static_cast<uint32_t> (uxly); uxly >>= 32;
   a += static_cast<uint32_t> (uylx); uylx >>= 32;
   w[1] = a; a >>= 32;
   uint64_t uxuy = ux * uy;
   a += uxly; a += uylx; a += uxuy;
   w[2] = a; a >>= 32;
   w[3] = a;
 }
diff --git a/liboctave/util/oct-inttypes.h b/liboctave/util/oct-inttypes.h
--- a/liboctave/util/oct-inttypes.h
+++ b/liboctave/util/oct-inttypes.h
@@ -76,28 +76,30 @@ REGISTER_INT_TYPE (uint64_t);
 
 // Rationale: Comparators have a single static method, rel(), that returns the
 // result of the binary relation. They also have two static boolean fields:
 // ltval, gtval determine the value of x OP y if x < y, x > y, respectively.
 #define REGISTER_OCTAVE_CMP_OP(NM,OP) \
   class NM \
     { \
     public: \
-      static const bool ltval = (0 OP 1), gtval = (1 OP 0); \
+      static const bool ltval = (0 OP 1); \
+      static const bool gtval = (1 OP 0); \
       template <class T> \
       static bool op (T x, T y) { return x OP y; } \
     }
 
 // We also provide two special relations: ct, yielding always true, and cf,
 // yielding always false.
 #define REGISTER_OCTAVE_CONST_OP(NM,value) \
   class NM \
     { \
     public: \
-      static const bool ltval = value, gtval = value; \
+      static const bool ltval = value; \
+      static const bool gtval = value; \
       template <class T> \
       static bool op (T, T) { return value; } \
     }
 
 // Handles non-homogeneous integer comparisons. Avoids doing useless tests.
 class octave_int_cmp_op
 {
   // This determines a suitable promotion type for T1 when meeting T2 in a
@@ -263,17 +265,19 @@ public:
   // Convert integer value.
   template <class S>
   static T
   truncate_int (const S& value)
   {
     // An exhaustive test whether the max and/or min check can be omitted.
     static const bool t_is_signed = std::numeric_limits<T>::is_signed;
     static const bool s_is_signed = std::numeric_limits<S>::is_signed;
-    static const int t_size = sizeof (T), s_size = sizeof (S);
+    static const int t_size = sizeof (T);
+    static const int s_size = sizeof (S);
+
     static const bool omit_chk_min =
       (! s_is_signed || (t_is_signed && t_size >= s_size));
     static const bool omit_chk_max =
       (t_size > s_size || (t_size == s_size
                            && (! t_is_signed || s_is_signed)));
     // If the check can be omitted, substitute constant false relation.
     typedef octave_int_cmp_op::cf cf;
     typedef octave_int_cmp_op::lt lt;
@@ -415,17 +419,18 @@ public:
 
   // Division with rounding to nearest. Note that / and % are probably
   // computed by a single instruction.
   static T
   div (T x, T y)
   {
     if (y != 0)
       {
-        T z = x / y, w = x % y;
+        T z = x / y;
+        T w = x % y;
         if (w >= y-w) z += 1;
         return z;
       }
     else
       {
         return x ? octave_int_base<T>::max_val () : 0;
       }
   }
@@ -605,17 +610,18 @@ public:
   static T
   add (T x, T y)
   {
 #ifdef HAVE_FAST_INT_OPS
     // The typecasts do nothing, but they are here to prevent an optimizing
     // compiler from interfering. Also, the signed operations on small types
     // actually return int.
     T u = static_cast<UT> (x) + static_cast<UT> (y);
-    T ux = u ^ x, uy = u ^ y;
+    T ux = u ^ x;
+    T uy = u ^ y;
     if ((ux & uy) < 0)
       {
         u = octave_int_base<T>::max_val () + __signbit (~u);
       }
     return u;
 #else
     // We shall carefully avoid anything that may overflow.
     T u;
@@ -646,17 +652,18 @@ public:
   static T
   sub (T x, T y)
   {
 #ifdef HAVE_FAST_INT_OPS
     // The typecasts do nothing, but they are here to prevent an optimizing
     // compiler from interfering. Also, the signed operations on small types
     // actually return int.
     T u = static_cast<UT> (x) - static_cast<UT> (y);
-    T ux = u ^ x, uy = u ^ ~y;
+    T ux = u ^ x;
+    T uy = u ^ ~y;
     if ((ux & uy) < 0)
       {
         u = octave_int_base<T>::max_val () + __signbit (~u);
       }
     return u;
 #else
     // We shall carefully avoid anything that may overflow.
     T u;
@@ -1232,21 +1239,23 @@ OCTAVE_INT_FLOAT_CMP_OP (==)
 OCTAVE_INT_FLOAT_CMP_OP (!=)
 
 #undef OCTAVE_INT_FLOAT_CMP_OP
 
 template <class T>
 octave_int<T>
 xmax (const octave_int<T>& x, const octave_int<T>& y)
 {
-  const T xv = x.value (), yv = y.value ();
+  const T xv = x.value ();
+  const T yv = y.value ();
   return octave_int<T> (xv >= yv ? xv : yv);
 }
 
 template <class T>
 octave_int<T>
 xmin (const octave_int<T>& x, const octave_int<T>& y)
 {
-  const T xv = x.value (), yv = y.value ();
+  const T xv = x.value ();
+  const T yv = y.value ();
   return octave_int<T> (xv <= yv ? xv : yv);
 }
 
 #endif
diff --git a/liboctave/util/oct-sort.cc b/liboctave/util/oct-sort.cc
--- a/liboctave/util/oct-sort.cc
+++ b/liboctave/util/oct-sort.cc
@@ -153,17 +153,18 @@ octave_sort<T>::binarysort (T *data, oct
                             octave_idx_type start, Comp comp)
 {
   if (start == 0)
     ++start;
 
   for (; start < nel; ++start)
     {
       /* set l to where *start belongs */
-      octave_idx_type l = 0, r = start;
+      octave_idx_type l = 0;
+      octave_idx_type r = start;
       T pivot = data[start];
       /* Invariants:
        * pivot >= all in [lo, l).
        * pivot  < all in [r, start).
        * The second is vacuously true at the start.
        */
       do
         {
@@ -197,17 +198,18 @@ octave_sort<T>::binarysort (T *data, oct
                             octave_idx_type start, Comp comp)
 {
   if (start == 0)
     ++start;
 
   for (; start < nel; ++start)
     {
       /* set l to where *start belongs */
-      octave_idx_type l = 0, r = start;
+      octave_idx_type l = 0;
+      octave_idx_type r = start;
       T pivot = data[start];
       /* Invariants:
        * pivot >= all in [lo, l).
        * pivot  < all in [r, start).
        * The second is vacuously true at the start.
        */
       do
         {
@@ -1689,17 +1691,18 @@ octave_sort<T>::is_sorted_rows (const T 
     {
       const T *lo = runs.top ().first;
       octave_idx_type n = runs.top ().second;
       runs.pop ();
       if (lo < lastrow)
         {
           // Not the final column.
           assert (n > 1);
-          const T *hi = lo + n, *lst = lo;
+          const T *hi = lo + n;
+          const T *lst = lo;
           for (lo++; lo < hi; lo++)
             {
               if (comp (*lst, *lo))
                 {
                   if (lo > lst + 1)
                     runs.push (run_t (lst + rows, lo - lst));
                   lst = lo;
                 }
@@ -1751,17 +1754,18 @@ octave_sort<T>::is_sorted_rows (const T 
 
 // The simple binary lookup.
 
 template <class T> template <class Comp>
 octave_idx_type
 octave_sort<T>::lookup (const T *data, octave_idx_type nel,
                         const T& value, Comp comp)
 {
-  octave_idx_type lo = 0, hi = nel;
+  octave_idx_type lo = 0;
+  octave_idx_type hi = nel;
 
   while (lo < hi)
     {
       octave_idx_type mid = lo + ((hi-lo) >> 1);
       if (comp (value, data[mid]))
         hi = mid;
       else
         lo = mid + 1;
@@ -1829,17 +1833,18 @@ octave_sort<T>::lookup (const T *data, o
 template <class T> template <class Comp>
 void
 octave_sort<T>::lookup_sorted (const T *data, octave_idx_type nel,
                                const T *values, octave_idx_type nvalues,
                                octave_idx_type *idx, bool rev, Comp comp)
 {
   if (rev)
     {
-      octave_idx_type i = 0, j = nvalues - 1;
+      octave_idx_type i = 0;
+      octave_idx_type j = nvalues - 1;
 
       if (nvalues > 0 && nel > 0)
         {
           while (true)
             {
               if (comp (values[j], data[i]))
                 {
                   idx[j] = i;
@@ -1851,17 +1856,18 @@ octave_sort<T>::lookup_sorted (const T *
             }
         }
 
       for (; j >= 0; j--)
         idx[j] = i;
     }
   else
     {
-      octave_idx_type i = 0, j = 0;
+      octave_idx_type i = 0;
+      octave_idx_type j = 0;
 
       if (nvalues > 0 && nel > 0)
         {
           while (true)
             {
               if (comp (values[j], data[i]))
                 {
                   idx[j] = i;
